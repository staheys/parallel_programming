# Оглавление

1. [Лекция 1](#лекция-1)
2. [Лекция 2](#лекция-2)
3. [Процессы и потоки в контексте Java](#процессы-и-потоки-в-контексте-java)
4. [Параллельные алгоритмы](#параллельные-алгоритмы)
5. [ПОТОКИ. ГОНКА ДАННЫХ И ДРУГИЕ ПРОБЛЕМЫ](#потоки-гонка-данных-и-другие-проблемы)
6. [Потокобезопасные структуры данных](#потокобезопасные-структуры-данных)
7. [Неизменяемые объекты (Immutable)](#неизменяемые-объекты-immutable)
8. [Обработка данных в очередях](#обработка-данных-в-очередях)
9. [Синхронизированные алгоритмы](#синхронизированные-алгоритмы)
10. [Взаимное исключение в распределённых системах](#взаимное-исключение-в-распределённых-системах)
11. [Асинхронная разработка](#асинхронная-разработка)
    
---


# <a name="лекция-1"></a>Лекция 1

## Задача, стоящая перед нами

Взять Maven или Gradle, сделать простой проект, делающий что-то и тесты к нему. Задача должна быть вычислительно сложной. Время работы от 3 до 10 сек. Примеры: вычисление площади под графиком


## Параллельные вычисления и многопоточное программирование

**Параллельные вычисления** позволяют выполнять несколько задач одновременно, что сокращает общее время выполнения программы. **Многопоточное программирование** — это подход, при котором в рамках одного процесса создаются несколько потоков для выполнения различных задач.

Преимущества многопоточного программирования:
- Улучшение производительности на многопроцессорных системах.
- Реализация более отзывчивых программ (например, GUI).
- Эффективное использование ресурсов процессора.

Основные вызовы:
- Потокобезопасность.
- Сложность отладки.
- Переключение контекста, которое может увеличивать накладные расходы.

## Архитектура параллельных вычислительных систем

Современные вычислительные системы имеют архитектуры, оптимизированные для параллельных вычислений:
1. **Многоядерные процессоры**:
   - Несколько ядер в одном процессоре.
   - Поддерживают аппаратную многопоточность.
2. **Системы с разделяемой памятью**:
   - Общая память для всех процессоров.
   - Требуется синхронизация доступа.
3. **Распределенные системы**:
   - Несколько узлов соединены сетью.
   - Каждый узел имеет свою локальную память.
4. **Графические процессоры (GPU)**:
   - Оптимизированы для массово параллельных вычислений.
   - Используются в машинном обучении и компьютерной графике.
5. **Кластерные системы**:
   - Объединение множества серверов для работы как одного суперкомпьютера.
   - Используют MPI или другие протоколы для связи между узлами.

Архитектура выбирается в зависимости от типа задач и уровня параллелизма, который требуется достичь.


# <a name="лекция-2"></a>Лекция 2


## Цель распараллеливания

Основная цель распараллеливания — это минимизация времени выполнения задач за счет их распределения на несколько процессоров или ядер. Это достигается путем:
- Разделения задач на независимые части.
- Одновременного выполнения нескольких частей задачи.

## Минимум времени выполнения работ

Эффективное распараллеливание позволяет:
- Уменьшить общее время выполнения программы.
- Снизить задержки при выполнении долгих операций.
- Увеличить пропускную способность системы.

---
 - Статическое планирование - заранее продумываем план и реализацию.
 - Динамическое планирование - продумываем в процессе работы системы.
---

## Классификация ЭВМ

 Классификация Флинна, основанная на том, как устроена в компьютере обработка данных. Согласно этой классификации все компьютеры (вычислительные комплексы) можно разделить на четыре класса - компьютеры с архитектурой:

 - SISD (Single Instruction stream - Single Data stream) - одиночный поток команд - одиночный поток данных. К этому классу относятся обычные "последовательные" компьютеры с фон-Неймановской архитектурой, когда команды программы выполняются последовательно, обрабатывая очередной элемент данных.
 - SIMD (Single Instruction stream - Multiple Data stream) - одиночный поток команд - множественный поток данных. К этому типу относятся компьютеры с векторными и матричными процессорами.
 - MISD (Multiple Instruction stream - Single Data stream) - множественный поток команд - одиночный поток данных. К этому типу можно отнести компьютеры с конвейерным типом обработки данных. Однако, многие полагают, что такие компьютеры следует относить к первому типу, а компьютеры класса MISD пока не созданы.
 - MIMD (Multiple Instruction stream - Multiple Data stream) - множественный поток команд - множественный поток данных. Класс MIMD чрезвычайно широк и в настоящее время в него попадают многие компьютеры достаточно разной архитектуры. Поэтому предлагаются другие классификации, позволяющие более точно классифицировать компьютеры, входящие в класс MIMD.

## Коэффициент полезной загрузки

Коэффициент полезной загрузки вычислительной системы показывает, насколько эффективно используются ресурсы. Высокий коэффициент достигается при равномерном распределении задач между всеми доступными ядрами/процессорами.

![Граф переходов](image.png)

Критический путь 1 -> 5 -> 2 -> 3 -> 4.

$T_i$ - время выполнения одной задачи. $T_{oi} = \sum_{i=0}^{n} T_i$  - общее время выполнения для одного процесора

$T_{o1} = 5$, $T_{o2} = 4$

$\dfrac{T_{o1}}{T_{o2}} = 1,25$ - Ускорение

$K_з = \dfrac{4 + 1}{4 * 2} = \dfrac{5}{8} = 0, 625$ - коэффициент загрузки

## Два уровня распараллеливания: по данным и по управлению

1. **Распараллеливание по данным**:
   - Задача разбивается на подзадачи, каждая из которых работает с отдельным набором данных.
   - Примеры: обработка массивов, параллельные вычисления в графике.
2. **Распараллеливание по управлению**:
   - Задача разбивается на подзадачи, каждая из которых выполняет свою логику.
   - Примеры: параллельная обработка запросов, многопоточная загрузка данных.

Эти два подхода могут сочетаться для достижения максимальной производительности.


# <a name="процессы-и-потоки-в-контексте-java"></a>Процессы и потоки в контексте Java

## Многозадачные ОС и функции, которые они обеспечивают

Современные операционные системы (ОС) — это многозадачные системы, способные выполнять несколько программ или процессов одновременно (или псевдопараллельно). ОС обеспечивает следующие основные функции:

1. **Управление процессами**  
   Создает, планирует, приостанавливает и возобновляет процессы. Гарантирует безопасное и предсказуемое взаимодействие процессов.
   
2. **Управление памятью**  
   Предоставляет механизм виртуальной памяти, защиту адресного пространства и т.д.

3. **Управление вводом-выводом**  
   Абстрагирует железо, предоставляет драйверы, очереди задач на устройствах ввода-вывода (диски, сети и т.д.).

4. **Распределение ресурсов**  
   Обеспечивает эффективное распределение ЦПУ, оперативной памяти, устройств ввода-вывода и других ресурсов между процессами.

### Закон Мура

Закон Мура (исторически сформулированный Горденом Муром) предсказывал экспоненциальный рост количества транзисторов на кристалле примерно каждые 18-24 месяца. Однако в последнее время упираемся в физические ограничения, рост стал замедляться, что приводит к стратегии увеличения числа ядер, а не только частоты процессора. Именно поэтому многопоточность и распараллеливание приобретают все большее значение.

## Процессы: владелец ресурсов

**Процесс** в ОС — это выполняющаяся программа, обладающая собственным адресным пространством, открытыми файлами (дескрипторами), сетевыми соединениями и другими системными ресурсами. Процесс изолирован от других процессов для безопасности и стабильности системы.  

- В большинстве систем у каждого процесса есть **уникальный идентификатор процесса (PID)**.  
- Процесс может состоять из одного или нескольких **потоков**.  
- В отличие от потоков, процессы взаимодействуют друг с другом через механизмы межпроцессного взаимодействия (IPC) — сокеты, каналы, очереди сообщений и т.д.

## Стратегии управления памятью

### Виртуальная память

Виртуальная память — это механизм, позволяющий создать для каждого процесса **абстракцию** непрерывного адресного пространства. Физическая память (ОЗУ) обычно меньше совокупного объема виртуальной памяти всех процессов, поэтому ОС может временно выгружать (swapping/paging) неиспользуемые части (страницы) памяти на диск (в файл подкачки) и подгружать их при необходимости обратно.

### Physical Address Extension (PAE)

PAE (Physical Address Extension) — технология, позволяющая 32-битным процессорам адресовать больше 4 ГБ оперативной памяти (до 64 ГБ). В современных 64-битных системах поддержка больших объёмов оперативной памяти уже встроена на уровне архитектуры.

## Потоки и стратегия управления ЦПУ

**Поток** (thread) — это "легковесный" поток управления внутри процесса. Все потоки одного процесса разделяют общее адресное пространство и общие ресурсы. В контексте Java потоки создаются с помощью класса `Thread` или через механизмы более высокоуровневой абстракции (например, `ExecutorService`, `ForkJoinPool` и т.д.).

### Множество потоков

Многопоточность позволяет одной программе более эффективно использовать ресурсы многоядерных/многопроцессорных систем. Некоторые преимущества многопоточности:

- Параллельное выполнение независимых задач.  
- Более быстрая реакция GUI-приложения (например, выделение фоновых потоков для долгих операций).  
- Упрощение структуры программы, когда разные задачи ведут себя как отдельные потоки (например, серверные приложения).

### Приоритеты потоков

У каждого потока в Java есть приоритет (`Thread.MIN_PRIORITY` … `Thread.MAX_PRIORITY`), который может влиять на планировщик ОС, но гарантии, что более приоритетные потоки всегда выполняются первыми, нет. Это лишь совет планировщику.  

### Жизненный цикл потока

Поток в Java проходит через несколько состояний:

1. **New** (создан)  
2. **Runnable** (готов к выполнению или выполняется)  
3. **Blocked / Waiting** (ожидает блокировки или события)  
4. **Terminated** (завершён)

Пример создания потока на Java:

```java
public class MyThreadExample {
    public static void main(String[] args) {
        Thread myThread = new Thread(() -> {
            System.out.println("Hello from thread: " + Thread.currentThread().getName());
        });
        
        // Ставим имя потока (опционально)
        myThread.setName("MyCustomThread");
        
        // Запускаем поток
        myThread.start();
        
        // Главный поток продолжит работу параллельно
        System.out.println("Hello from main thread: " + Thread.currentThread().getName());
    }
}
```

## Прерывания (программные и аппаратные)

- **Аппаратные прерывания** возникают, когда устройство сигнализирует процессору (например, при завершении операции ввода-вывода).  
- **Программные (или программные исключения)** возникают при ошибках в работе программ (деление на ноль, некорректный доступ к памяти) или вызовах ОС (системные вызовы).

ОС обрабатывает прерывания, переключаясь в контекст **обработчика прерываний (interrupt handler)**, после чего возвращается к прерванному коду.

## Процессы, потоки и данные

Главное отличие между процессами и потоками — **степень изоляции**:

- Процессы **изолированы** и имеют разные адресные пространства.  
- Потоки в рамках одного процесса **разделяют** общие данные.  

Из-за общей памяти между потоками становится проще обмениваться данными, но это требует механизмов синхронизации (например, `synchronized`, `Lock`, `Atomic` переменные и т.д. в Java).

## Переключение контекста и параллельное выполнение

### Проблема переключения контекста

Когда ОС переключается от одного процесса к другому, происходит **context switch**: сохранение состояния регистров и других данных текущего процесса и загрузка состояния другого процесса. Это сравнительно "тяжёлый" процесс.  

У потоков внутри одного процесса переключение контекста дешевле, чем между процессами, потому что они разделяют общее адресное пространство. Однако все равно есть накладные расходы на сохранение регистров, стека и прочих ресурсов.

### Параллелизм против конкурентности

- **Параллелизм** — реальное одновременное выполнение на нескольких ядрах/процессорах.
- **Конкурентность** (Concurrency) — способность операционной системы "делить" время ЦПУ между несколькими потоками (могут выполняться псевдопараллельно на одном ядре).

## Контекст процесса и контекст потока

- **Контекст процесса** включает в себя:  
  - Свое собственное адресное пространство  
  - Открытые файлы/сокеты  
  - Сигналы (POSIX) и проч.  
- **Контекст потока** включает в себя:  
  - Указатель стека / собственный стек  
  - Регистры процессора (EAX, ECX, и т.д.)  
  - Локальные переменные, используемые в потоке

## Взгляд программиста

С точки зрения Java-разработчика, процессы обычно запускаются посредством:

- Запуска отдельных JVM (каждая JVM — отдельный процесс).  
- Создания внешних процессов с помощью `ProcessBuilder`.  

Потоки же — это более "легковесный" путь параллелить задачи внутри одной JVM.

## Когда нужны потоки?

1. **Реактивность**: при длительных операциях ввода-вывода (сетевые запросы, чтение файлов) использование потоков позволяет не блокировать главный поток.  
2. **Параллельные вычисления**: если у вас многоядерный процессор, вы можете одновременно решать подзадачи.  
3. **Задачи с разделением по управлению**: разные потоки могут отвечать за разные компоненты приложения (логирование, сетевые соединения, фоновая обработка и т.д.).  
4. **Задачи с распараллеливанием по данным**: поток обрабатывает часть массива, далее результаты собираются воедино.

Пример параллелизации по данным в Java (используем `ExecutorService`):

```java
import java.util.concurrent.*;

public class ParallelSum {
    private static final int THREADS_COUNT = 4;
    private static final int ARRAY_SIZE = 10_000_000;
    
    public static void main(String[] args) throws InterruptedException, ExecutionException {
        // Генерируем большой массив
        int[] data = new int[ARRAY_SIZE];
        for (int i = 0; i < ARRAY_SIZE; i++) {
            data[i] = 1; // для простоты
        }

        ExecutorService executor = Executors.newFixedThreadPool(THREADS_COUNT);

        // Делим массив на части
        int chunkSize = ARRAY_SIZE / THREADS_COUNT;
        Future<Long>[] results = new Future[THREADS_COUNT];
        
        for (int i = 0; i < THREADS_COUNT; i++) {
            final int start = i * chunkSize;
            final int end = (i == THREADS_COUNT - 1) ? ARRAY_SIZE : start + chunkSize;
            
            results[i] = executor.submit(() -> {
                long sum = 0;
                for (int j = start; j < end; j++) {
                    sum += data[j];
                }
                return sum;
            });
        }

        long totalSum = 0;
        for (Future<Long> future : results) {
            totalSum += future.get();
        }

        executor.shutdown();

        System.out.println("Sum: " + totalSum);
    }
}
```

## Потокобезопасные методы

При работе с общими ресурсами (переменные, коллекции) несколько потоков могут изменить состояние одновременно, что ведёт к непредсказуемым результатам (race condition). Для предотвращения таких ошибок используются **потокобезопасные** (thread-safe) методы и структуры:

1. **Синхронизированные блоки и методы**:

```java
public synchronized void increment() {
    counter++;
}
```

2. **Блокировки (Lock)**:  
   Использование `java.util.concurrent.locks.Lock`:

```java
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class Counter {
    private long value = 0;
    private Lock lock = new ReentrantLock();

    public void increment() {
        lock.lock();
        try {
            value++;
        } finally {
            lock.unlock();
        }
    }

    public long getValue() {
        return value;
    }
}
```

3. **Специальные классы**:  
   - `AtomicInteger`, `AtomicLong`, `AtomicReference` и т.п.  
   - Коллекции из пакета `java.util.concurrent` (например, `ConcurrentHashMap`, `CopyOnWriteArrayList` и т.п.).

Потокобезопасность важна для корректной работы программ, где данные разделяются между потоками.

---

**Итог**:  
- Процессы — более "тяжелые" единицы выполнения, каждый со своим адресным пространством.  
- Потоки — единицы выполнения внутри одного процесса, разделяющие общее адресное пространство, но более "легковесные" и требующие дополнительных мер синхронизации.  
- ОС управляет процессами и потоками, распределяет ЦПУ и память, обрабатывает прерывания, обеспечивает механизмы межпроцессного взаимодействия.  
- Java предлагает удобные высокоуровневые API для работы с потоками (часть `java.util.concurrent`), но при этом важно понимать базовые концепции процессов и потоков, чтобы эффективно писать производительные и безопасные многопоточные приложения.

Параллельные алгоритмы позволяют эффективно использовать многоядерные и многопроцессорные системы для ускорения вычислений. Ниже приведён обзор основных подходов к распараллеливанию циклов, рекурсий, методов суммирования, вычисления интегралов, числа \(\pi\), а также краткие сведения о параллельных методах в линейной алгебре и сортировке.

# <a name="параллельные-алгоритмы"></a>Параллельные алгоритмы

## Циклы: инициализация, тело, обработка результатов. Тело без побочных эффектов. Рекурсия

Любой цикл обычно состоит из:
- Инициализации (подготовка параметров, переменных и т. п.),
- Тела цикла (основные действия),
- Обработки результатов (суммирование частичных результатов и т. д.).

Чтобы эффективно распараллелить цикл, желательно, чтобы его тело было **без побочных эффектов**, то есть не изменяло глобальные переменные и не зависело от общих ресурсов. В таком случае можно легко разделять работу между потоками без сложной синхронизации.

Аналогичное правило действует при рекурсивных вызовах: если каждая рекурсивная ветвь не зависит от остальных, вычисления легко распараллеливаются (например, рекурсивные обходы деревьев, divide-and-conquer алгоритмы).



## Распараллеливание цикла

Рассмотрим задачу суммирования большого массива чисел. Последовательная реализация может выглядеть так:

```
double sum = 0.0;
for (int i = 0; i < n; i++) {
    sum += arr[i];
}
```

Чтобы распараллелить:
- Создают несколько потоков,
- Каждый поток обрабатывает часть данных (блочно или шагово),
- Собирают частичные суммы в итоговый результат.

Основные приёмы параллельного суммирования:
1. **“Пирамидка” (дерево суммирования)**: сначала потоки вычисляют свои локальные суммы, затем эти суммы объединяются в дереве редукции, уменьшая накладные расходы на синхронизацию.
2. **“Блоки”**: каждый поток получает непрерывный блок массива (например, первый поток считает от 0 до k-1 элемент, второй от k до 2k-1 и т.д.).
3. **Дополнительная память**: вместо общей глобальной переменной sum, которая требует синхронизации, у каждого потока своя локальная переменная. После окончания работы потоков результаты суммируются в одном потоке.

## Варианты сегментирования: блочный и шаговый

- **Блочный (block partitioning)**: массив делится на последовательные блоки (например, если n = 1000 и потоков 4, то потоку №1 достаются индексы [0..249], потоку №2 [250..499], и т.д.).
- **Шаговый (cyclic / interleaving)**: поток №1 обрабатывает индексы 0, 4, 8, 12..., поток №2 — 1, 5, 9, 13..., поток №3 — 2, 6, 10, 14..., поток №4 — 3, 7, 11, 15.... Такой подход бывает полезен, если данные сильно «кластеризованы» и хочется распределить нагрузку более равномерно.

## Суммирование рядов. Сходимость. Погрешность. Сегментация как переход к сумме конечного ряда

Многие бесконечные ряды (например, ряды для функций \(\sin x\), \(\ln x\) и т. п.) можно приближённо вычислять, беря лишь первые \(N\) слагаемых, при этом контролируя погрешность.  

Чтобы распараллелить вычисление ряда, можно разбивать эти \(N\) слагаемых между несколькими потоками (аналогично сумме массива). Важно понимать, насколько быстро сходится ряд, чтобы правильно выбрать \(N\).

## Тригонометрические функции. Ряд Тейлора. Рекуррентные отношения. Эффективность распараллеливания

Тригонометрические и экспоненциальные функции часто вычисляют через ряды Тейлора или рекуррентные формулы:
\[
\sin x = \sum_{k=0}^{\infty} (-1)^k \frac{x^{2k+1}}{(2k+1)!}, 
\quad
\cos x = \sum_{k=0}^{\infty} (-1)^k \frac{x^{2k}}{(2k)!},
\]
и так далее.

Для распараллеливания ряда Тейлора применяют тот же принцип: раздать группам потоков различные наборы членов ряда и аккуратно собрать результат. Но часто практичнее использовать высокопроизводительные библиотеки (например, из «math»-пакетов или специализированных библиотек на С/С++ с векторизацией), чем писать собственную распараллеленную реализацию тригонометрии.

Иногда выгоднее использовать **рекуррентные отношения** (например, для вычисления \(\sin(x+\Delta)\) через \(\sin x\) и \(\cos x\)), если их можно эффективно распараллелить или векторизовать.

## Вычисление определённого интеграла

Для численного интегрирования \(\int_a^b f(x)\,dx\) часто используют:
1. **Метод прямоугольников (метод Римана)**,
2. **Метод трапеций**,
3. Более сложные методы (Симпсона, Гаусса и т. п.).

Чтобы увеличить точность, повышают число разбиений отрезка \([a,b]\). В параллельном варианте:
- Делят исходный отрезок на несколько подотрезков,
- Запускают несколько потоков, каждый считает свою часть интеграла,
- Суммируют все части.

Таким образом, есть два основных способа:
1. Разбить \([a,b]\) на большие блоки (каждому потоку свой блок).  
2. “Шаговая” схема, когда поток №k считает точки \(x_i\) с индексами, дающими остаток \(k\) по модулю числа потоков.

## Вычисление числа \(\pi\)

Существует масса способов параллельно вычислять \(\pi\). Несколько популярных подходов:

1. **Через \( \arcsin(x)\) или ряды Лейбница**  
   Пример: \(\pi = 4 \sum_{k=0}^{\infty} \frac{(-1)^k}{2k+1}\).  
   Как и прежде, достаточно распараллелить сумму ряда.

2. **Определённый интеграл функции круга**  
   \(\pi = 4 \int_0^1 \sqrt{1 - x^2}\,dx\).  
   Делим отрезок \([0,1]\) на подотрезки и распараллеливаем вычисление.

3. **Площадь круга как многогранника**  
   Приближаем окружность многоугольником с большим количеством сторон. Чем больше сторон, тем ближе площадь к \(\pi \cdot R^2\). Задачу подсчёта вершин и площадей тоже можно распараллелить.

4. **Метод Монте-Карло**  
   Равномерно “бросаем точки” в квадрат \([0,1]\times[0,1]\). Доля точек, попавших внутрь четверти единичного круга, стремится к \(\pi/4\). Генерация и подсчёт внутри круга прекрасно распараллеливаются.

5. **Метод интегрирования единичной функции**  
   В квадрате \([0,1]\times[0,1]\) интегрируем индикаторную функцию круга. По сути, это та же идея Монте-Карло, только в других формулировках.

## Задачи линейной алгебры

Одни из самых ресурсоёмких задач — операции над матрицами. Параллелизация тут особенно эффективна.

1. **Умножение матриц**  
   Если у нас есть две матрицы \(A\) (размер \(n \times m\)) и \(B\) (размер \(m \times k\)), то результатом будет матрица \(C\) (размер \(n \times k\)). Элемент \(C_{ij}\) вычисляется как скалярное произведение i-й строки матрицы \(A\) и j-го столбца матрицы \(B\).  
   В параллельном варианте блоки матриц (или строки и столбцы) распределяются по потокам.

2. **Умножение разреженных матриц**  
   При умножении разреженных матриц важно эффективно хранить и обрабатывать ненулевые элементы. На практике используют структуры данных (CSR, CSC и т. п.). Параллелизация учитывает разреженность, чтобы не тратить ресурсы на нули.

3. **Хранение одной матрицы по строкам, другой по столбцам**  
   Классический способ ускорить умножение в памяти — хранить одну матрицу в построчном формате (row-major), а другую в по-столбцовом (column-major). При вычислении скалярного произведения кеш и кэш-локальность срабатывают эффективнее.

## Сортировка

Сортировка больших массивов — типичный пример разделяй-и-властвуй (divide-and-conquer):
- **Параллельная быстрая сортировка (quick sort)**: массив рекурсивно разбивается на подмассивы, и каждая часть сортируется в отдельном потоке.
- **Сортировка слиянием** (merge sort): параллелим разделение и последующее слияние.  
- **Поразрядная сортировка (radix sort)** и некоторые другие алгоритмы могут быть эффективно векторизованы или распараллелены.

Основная идея — рекурсивно разбиваем задачу и распараллеливаем независимые части. Если же массив невелик, нет смысла плодить потоки — накладные расходы на переключение могут превысить выигрыш.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Итого, при распараллеливании алгоритмов важно:
1. Найти, какие части задачи могут исполняться независимо (без гонок за общие ресурсы).  
2. Разбить данные и код по потокам, используя подходящие схемы сегментирования (блочное, шаговое, дерево суммирования и пр.).  
3. Тщательно продумать синхронизацию, чтобы избежать конфликтов при записи в общие переменные.  
4. Оценивать затраты на межпоточное взаимодействие (synchronization, IPC) и переключение контекста. Часто для вычислительных задач такой подход окупается, особенно на больших объёмах данных.  

# <a name="потоки-гонка-данных-и-другие-проблемы"></a>ПОТОКИ. ГОНКА ДАННЫХ И ДРУГИЕ ПРОБЛЕМЫ
Тема многопоточности тесно связана с рядом сложностей, возникающих при одновременном доступе к общим ресурсам, а именно: гонка данных (race condition), повреждение данных (data corruption) и тупики (deadlock). Ниже приводится подробное описание этих проблем и методов их решения.


## ОБЩИЕ ПОНЯТИЯ О МНОГОПОТОЧНОСТИ

В многопоточном приложении несколько потоков (thread) могут выполняться **параллельно** (если есть несколько ядер) или **конкурентно** (если ядер меньше, чем потоков — процессор переключается между ними). В любом случае потоки могут разделять общие ресурсы (память, файлы, сетевые соединения), что приводит к необходимости координации действий потоков, чтобы избежать ошибок.

В контексте Java каждый поток — это экземпляр класса `Thread` либо задача, выполняющаяся в `ExecutorService`. Если не соблюдать меры синхронизации, возникает риск некорректного или непредсказуемого поведения при одновременном доступе к одним и тем же данным.

## ГОНКА ДАННЫХ (RACE CONDITION)

**Гонка данных** — это ситуация, при которой результат вычисления зависит от порядка (времени) планирования потоков при доступе к разделяемому ресурсу. Если порядок выполнения операций меняется, то итог может отличаться или приводить к ошибкам.

Простейший пример — несколько потоков увеличивают общий счётчик:

    class SharedCounter {
        private int count = 0;

        public void increment() {
            count++;
        }

        public int getCount() {
            return count;
        }
    }

Если из разных потоков часто вызывается `increment()`, может сложиться ситуация, когда:
1. Поток А читает `count` (предположим, значение = 10).  
2. До того как Поток А запишет новое значение (10+1=11), планировщик переключает контекст на Поток B.  
3. Поток B тоже читает `count`, видит 10, увеличивает до 11 и записывает.  
4. Возвращаемся к Потоку А, он завершает свою операцию и тоже записывает 11.  
В итоге увеличили счётчик один раз вместо двух, хотя два потока должны были сделать +1 каждый.  

Поэтому даже простая операция `count++` не является атомарной и может привести к некорректным результатам без синхронизации.

### КАК ИЗБЕЖАТЬ ГОНКИ ДАННЫХ
- Использовать ключевое слово **synchronized** в Java:
  
      public synchronized void increment() {
          count++;
      }

  Тогда в один момент времени только один поток может выполнять код внутри синхронизированного метода/блока.

- Применять классы из `java.util.concurrent.atomic` (например, `AtomicInteger`, `AtomicLong`). Они обеспечивают атомарные операции без необходимости ставить блокировку:
  
      private AtomicInteger atomicCount = new AtomicInteger();
      
      public void increment() {
          atomicCount.incrementAndGet();
      }

- Использовать другие механизмы синхронизации, такие как **ReentrantLock**, **ReadWriteLock**, **Semaphore** и т. д., если нужна более гибкая или тонкая стратегия блокировок.

### ГЛАВНОЕ О ГОНКЕ ДАННЫХ  
- Часто трудно воспроизвести: может проявляться только на некоторых машинах, в редких обстоятельствах, при высоких нагрузках.  
- Исправление требует понимания, какие объекты и данные “шарятся” между потоками.  
- Правильная синхронизация гарантирует **порядок доступа** к данным.

## ПОВРЕЖДЕНИЕ ДАННЫХ (DATA CORRUPTION)

**Повреждение данных** — это частный случай проблем многопоточности, когда из-за отсутствия (или неправильной) синхронизации данные оказываются в неконсистентном, “сломанном” состоянии. Иногда это называют “разорванными” данными или “неконсистентным кэшем”.

3.1. ПРИМЕР НЕКОНСИСТЕНТНОСТИ
Допустим, мы имеем структуру (класс), состоящую из нескольких полей, которые должны всегда меняться атомарно, все сразу. Если один поток обновляет часть полей, а второй в тот же момент читает эти поля, возможно, второй поток увидит “смешанное” состояние (некоторые поля уже обновлены, а некоторые — нет).

3.2. МЕХАНИЗМЫ ПРЕДОТВРАЩЕНИЯ ПОВРЕЖДЕНИЯ ДАННЫХ
- Использовать синхронизированные методы или блоки `synchronized` при любом обновлении сложных объектов.
- Если требуется “снять копию” сразу нескольких полей, тоже оборачивать это чтение в синхронизированный блок, чтобы никто параллельно не вносил изменения.
- Применять неизменяемые (immutable) объекты, если это возможно. В Java это классы, у которых все поля `final` и нет сеттеров (String, Integer, LocalDateTime и т. п.). Если объект неизменяемый, многопоточный доступ к нему безопасен.
- Использовать специализированные механизмы: **volatile**, **Atomics**, **StampedLock**, **ConcurrentHashMap** и т.д.

## ТУПИКИ (DEADLOCK)

**Тупик (Deadlock)** — это ситуация, в которой два (или более) потока заблокированы навсегда, ожидая ресурсы, которые друг у друга удерживаются. Проще всего иллюстрировать на примере:

- Поток A захватывает блокировку для объекта 1, затем хочет получить блокировку для объекта 2.  
- Поток B захватил блокировку для объекта 2, затем хочет получить блокировку для объекта 1.  
- Каждый поток ждёт, пока второй освободит нужную ему блокировку, и они никогда не освободят.

### УСЛОВИЯ ВОЗНИКНОВЕНИЯ DEADLOCK (ПО КОФМЕНУ)
1. Взаимное исключение (mutex) — ресурсы, которые нельзя использовать совместно (только один поток владеет ресурсом).  
2. Удержание и ожидание (hold and wait) — поток, уже владея одним ресурсом, пытается заполучить второй (и не отпускает первый).  
3. Отсутствие принудительного освобождения (no preemption) — нельзя забрать ресурс у потока принудительно, он сам должен его освободить.  
4. Цикл ожидания (circular wait) — существует набор потоков, каждый из которых ждёт ресурс, удерживаемый следующим по цепочке.

Когда все четыре условия соблюдены, может возникнуть тупик.

### СПОСОБЫ ПРЕДОТВРАЩЕНИЯ И РЕШЕНИЯ DEADLOCK
- **Иерархия захвата ресурсов (Lock Ordering)**: договориться, в каком порядке брать блокировки. Например, всегда сначала блокировать объект с меньшим id, потом с большим.  
- **Попытка блокировки с таймаутом**: использовать методы вроде `tryLock(long timeout, TimeUnit unit)`, чтобы поток мог отказаться от ожидания, если не получается захватить ресурс.  
- **Избегать избыточных блокировок**: часто можно перепроектировать код так, чтобы не держать сразу две и более блокировки.  
- **Детекция тупиков**: существуют алгоритмы (в некоторых системах) для отслеживания цикла ожидания и принудительного завершения одного из процессов.

## ДРУГИЕ ПРОБЛЕМЫ МНОГОПОТОЧНОСТИ

Кроме гонки данных, повреждения данных и тупиков, есть ещё несколько распространённых проблем:

### **STARVATION (ГОЛОДАНИЕ)**  
Поток может не получать доступ к ресурсу (или почти не получать процессорное время) из-за того, что другие потоки с более высоким приоритетом постоянно перехватывают управление. Как следствие, “голодающий” поток продвигается крайне медленно, хотя потенциально “жив”.

### **LIVЕLOCK (ВЗАИМНОЕ БЛОКИРОВАНИЕ)**  
Вроде бы потоки не заблокированы “навсегда”, они постоянно меняют состояние (пытаются что-то сделать), но в итоге система не продвигается (например, два потока вежливо пытаются “уступить” блокировку друг другу бесконечно).

### **НЕКОРРЕКТНОЕ ИСПОЛЬЗОВАНИЕ WAIT/NOTIFY**  
В Java можно использовать методы `wait()`, `notify()`, `notifyAll()` для организации синхронизации. Ошибки при их использовании (забыли `synchronized` блок, вызвали `notify()` не на том объекте и т. д.) могут приводить к непредсказуемому поведению и “подвисанию” потоков.

## ОБОБЩЁННЫЕ РЕКОМЕНДАЦИИ ПО РАБОТЕ С ПОТОКАМИ

2. **Идентифицируйте разделяемое состояние**. Любые переменные и объекты, которые могут быть доступны нескольким потокам одновременно, потенциально представляют опасность.
3. **Минимизируйте совместное использование**. Чем меньше данные разделяются, тем легче их защитить или избежать синхронизации вообще.
4. **Используйте правильный инструмент синхронизации**. Иногда хватает `synchronized`, иногда лучше `Lock`, а порой достаточно атомарных классов.  
5. **Соблюдайте единый порядок захвата ресурсов** (Lock Ordering). Это одно из самых надёжных решений против deadlock.
6. **Делайте объекты неизменяемыми**, если возможно. Неизменяемые объекты можно безопасно передавать между потоками без дополнительных блокировок.  
7. **Изучайте библиотеки из `java.util.concurrent`**: `ConcurrentHashMap`, `CopyOnWriteArrayList`, `BlockingQueue`, `Semaphore`, `ExecutorService` и т.д. Они предоставляют проверенные и оптимизированные решения распространённых задач многопоточности.

## ЗАКЛЮЧЕНИЕ

Многопоточность помогает увеличить производительность и улучшить реактивность приложения, но взамен вносит сложности, с которыми не сталкиваются при однопоточном исполнении. Гонка данных, повреждение данных и тупики — три наиболее критические проблемы, приводящие к неправильным результатам или полной остановке программы.

Для их предотвращения необходимо:
- Явно управлять доступом к разделяемым ресурсам,
- Правильно проектировать архитектуру приложения,
- Понимать, как работают блокировки и другие механизмы синхронизации в Java,
- Использовать надёжные и отлаженные структуры данных из стандартной библиотеки.

Только при грамотном учёте всех нюансов многопоточности можно добиться корректной, стабильной и производительной работы приложения.

# <a name="потокобезопасные-структуры-данных-на-примере-java"></a>Потокобезопасные структуры данных

Многопоточность нередко сопровождается проблемами при доступе к общим структурам данных. В Java предусмотрен ряд готовых решений, которые упрощают написание корректного кода для многопоточных приложений. Ниже рассмотрены основные потокобезопасные контейнеры, а также атомарные классы.

---

## Потокобезопасные контейнеры

Потокобезопасные (thread-safe) контейнеры — это коллекции, обеспечивающие корректную работу при одновременном доступе из нескольких потоков без необходимости внешней синхронизации (или же позволяющие минимизировать её).

### ConcurrentHashMap

- **Описание**: Потокобезопасная реализация `Map`, которая разбивает данные на сегменты или использует CAS-операции (в более новых реализациях) для минимизации блокировок.  
- **Особенности**:  
  - Позволяет параллельно читать и модифицировать разные части мапы.  
  - Нет необходимости оборачивать операции в synchronized-блоки.  
  - Итератор (iterator) предоставляется «слабосогласованным» (weakly consistent), то есть не блокирует всю коллекцию во время обхода и может пропускать некоторые изменения или видеть их частично.  
- **Пример использования**:
  ```java
  ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();
  map.put("One", 1);
  map.put("Two", 2);
  // Одновременные операции из разных потоков
  int oldValue = map.replace("One", 1, 11);
  ```
  
### CopyOnWriteArrayList

- **Описание**: Имплементация `List`, при изменении которой (добавление, удаление, обновление) создаётся **копия** внутреннего массива.  
- **Особенности**:  
  - Хорошо подходит для сценариев «чаще читаем, реже записываем».  
  - Операции чтения не блокируют коллекцию и могут выполнять работу в параллели.  
  - При большом числе модификаций может возрастать расход памяти и снижаться производительность из-за частых копирований.  
- **Пример использования**:
  ```java
  CopyOnWriteArrayList<String> list = new CopyOnWriteArrayList<>();
  list.add("A");
  list.add("B");
  // Чтение из многих потоков и редкие записи
  ```
  
### BlockingQueue

- **Описание**: Интерфейс очереди, поддерживающий операции, которые **блокируют** поток, если очередь пуста (при попытке `take()`) или заполнена (при попытке `put()`).  
- **Реализации**:  
  - `ArrayBlockingQueue` (固定 размер),  
  - `LinkedBlockingQueue` (нефиксированный верхний лимит или фиксированный),  
  - `PriorityBlockingQueue` (приоритетная очередь).  
- **Основное применение**:  
  - Связь между потоками «производитель/потребитель» (producer/consumer).  
  - Если очередь пуста — потребитель блокируется, если полна — производитель блокируется.  
- **Пример использования**:
  ```java
  BlockingQueue<Integer> queue = new LinkedBlockingQueue<>(10);

  // Поток-производитель
  new Thread(() -> {
      try {
          for (int i = 0; i < 100; i++) {
              queue.put(i);
          }
      } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
      }
  }).start();

  // Поток-потребитель
  new Thread(() -> {
      try {
          while (true) {
              Integer value = queue.take();
              System.out.println("Consumed: " + value);
          }
      } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
      }
  }).start();
  ```

### ConcurrentLinkedQueue / ConcurrentLinkedDeque

- **Описание**: Неблокирующие (lock-free) очереди/деки (двусторонние очереди).  
- **Особенности**:  
  - Используют атомарные операции для управления элементами списка, исключая глобальные блокировки.  
  - Прекрасно подходят для высоконагруженных систем, где потокам необходимо быстро класть и забирать элементы (queue / deque).  
- **Пример использования**:
  ```java
  ConcurrentLinkedQueue<String> queue = new ConcurrentLinkedQueue<>();
  queue.offer("First");
  queue.offer("Second");
  String head = queue.poll();
  ```

---

## Атомарные классы (Atomic)

Атомарные классы из пакета `java.util.concurrent.atomic` предоставляют операции над примитивами и объектами, которые **гарантированно** выполняются атомарно (как единое действие, без гонок данных при корректной публикации переменных).

### AtomicInteger, AtomicLong, AtomicBoolean

- **Описание**: Позволяют атомарно инкрементировать, декрементировать, устанавливать, читать и делать сравнение-с-установкой (compare-and-set, CAS) для целочисленных, долгих и булевых значений.  
- **Методы**:  
  - `get()` / `set(newValue)` — чтение/запись,  
  - `incrementAndGet()`, `decrementAndGet()`, `addAndGet(delta)` — атомарные арифметические операции,  
  - `compareAndSet(expected, update)` — атомарная проверка и установка.  
- **Пример использования**:
  ```java
  AtomicInteger atomicCount = new AtomicInteger(0);
  atomicCount.incrementAndGet();  // возвращает новое значение
  atomicCount.addAndGet(5);       // увеличивает на 5 и возвращает
  ```

### AtomicReference

- **Описание**: Хранит ссылку на объект, позволяет атомарно обновлять эту ссылку (например, атомарно менять объект при соблюдении условия).  
- **Применение**:  
  - Реализация неблокирующих структур данных.  
  - Хранение конфигурационных объектов (иммутабельных), которые можно менять «разом».  
- **Пример использования**:
  ```java
  AtomicReference<String> atomicRef = new AtomicReference<>("initial");
  boolean updated = atomicRef.compareAndSet("initial", "new value");
  ```

### AtomicStampedReference / AtomicMarkableReference

- **Описание**: Позволяют не только атомарно обновлять ссылку, но и отслеживать версию (штамп) или логический маркер. Это помогает решить проблему **ABA** (когда ссылка успела поменяться и вернуться к исходному объекту, и CAS не замечает изменений).  
- **Пример**:
  ```java
  AtomicStampedReference<String> stampedRef = 
      new AtomicStampedReference<>("init", 0);

  int[] stampHolder = new int[1];
  String currentRef = stampedRef.get(stampHolder);
  int currentStamp = stampHolder[0];

  boolean success = stampedRef.compareAndSet(
      currentRef,
      "updated",
      currentStamp,
      currentStamp + 1
  );
  ```

---

## Итог

- **Потокобезопасные контейнеры** (такие как `ConcurrentHashMap`, `CopyOnWriteArrayList`, различные `BlockingQueue` и `ConcurrentLinkedQueue/Deque`) значительно упрощают написание многопоточных приложений. Они берут на себя сложную логику синхронизации (или используют неблокирующие структуры) и обеспечивают корректный доступ из множества потоков.  
- **Атомарные классы** (Atomic) дают возможность производить атомарные операции над примитивами (Integer, Long, Boolean) и ссылками, что часто упрощает реализацию высокопроизводительных неблокирующих алгоритмов без использования классических блокировок `synchronized`.  

Применение этих инструментов в Java позволяет снизить вероятность гонок данных и повысить пропускную способность многопоточных программ. Главное — осознавать границы их применения (например, `CopyOnWriteArrayList` эффективен при редких изменениях, `AtomicReference` не спасёт от сложных инвариантов в объекте) и понимать, что некоторые ситуации всё же могут потребовать дополнительных механизмов синхронизации.

# <a name="неизменяемые-объекты-immutable"></a>Неизменяемые объекты (Immutable)

Неизменяемые (immutable) объекты — это объекты, состояние которых не может быть изменено после создания. С точки зрения проектирования ПО и многопоточности они обладают целым рядом преимуществ.  

## Зачем нужны immutable объекты?

### 1. Упрощение многопоточности
- **Безопасность при параллельном доступе**: если объект нельзя изменить, то нет риска гонки данных (race condition) при его одновременном чтении из нескольких потоков.  
- **Отсутствие необходимости в синхронизации**: не нужно заботиться о блокировках (synchronized, Lock) или атомарных операциях для обеспечения целостности, так как объект не меняется.  
- **Упрощённая кэш-совместимость**: JVM может кэшировать неизменяемый объект и выдавать одинаковую ссылку разным потокам, не опасаясь противоречий.

### 2. Упрощение разработки ПО
- **Легче понимать и отлаживать**: модель состояния становится проще, так как объект, однажды созданный, уже не изменится.  
- **Безопасное повторное использование**: один и тот же неизменяемый объект можно передавать в разные части системы, не волнуясь, что кто-то «случайно» или специально изменит его.  
- **Исключение побочных эффектов**: функции, которые возвращают неизменяемые объекты, гарантированно не модифицируют их. Это особенно важно в функциональных стилях программирования.

---

## Правила создания immutable объектов

Чтобы класс в Java считался по-настоящему **неизменяемым**, необходимо придерживаться следующих правил:

### 1. Без setter’ов
Не должно быть методов, которые изменяют состояние объекта после его создания. То есть, никакого `setSomething(...)`.

### 2. Без модифицирующих методов
Все методы, которые могли бы изменить состояние, вместо этого **возвращают новый объект**, отражающий изменения, либо не допускают изменений вообще.  
Пример:  
```java
public class ImmutablePoint {
    private final int x;
    private final int y;

    public ImmutablePoint(int x, int y) {
        this.x = x;
        this.y = y;
    }

    // Нет методов вида setX() или setY()

    public int getX() { return x; }
    public int getY() { return y; }

    // "Смещение" возвращает НОВЫЙ объект
    public ImmutablePoint move(int dx, int dy) {
        return new ImmutablePoint(this.x + dx, this.y + dy);
    }
}
```

### 3. Поля должны быть `private` и `final`
- **private**: чтобы доступ к полям был только внутри класса, исключая обходные изменения снаружи.  
- **final**: чтобы поле не могло быть изменено после инициализации в конструкторе.

### 4. Правильная инициализация всех полей в конструкторе
- Все необходимые значения должны передаваться в конструктор и инициализироваться ровно один раз.  
- После выхода из конструктора объект уже находится в полностью готовом состоянии.

### 5. Неизменяемость ссылочных полей, если они есть
Если в классе есть поля, указывающие на другие объекты (например, `List`, `Date`, или любую другую изменяемую структуру), то важно либо сделать их тоже неизменяемыми, либо обеспечить копирование (защищённое копирование) при входе и выходе.

#### Пример сложности с изменяемым полем
Предположим, у нас есть неизменяемый класс, который содержит `Date` (класс `Date` в Java — изменяемый):
```java
public class Person {
    private final String name;
    private final Date birthDate; // Date - изменяемый класс

    public Person(String name, Date birthDate) {
        this.name = name;
        // Чтобы избежать изменения извне, нужно сделать копию:
        this.birthDate = new Date(birthDate.getTime());
    }

    public String getName() {
        return name;
    }

    // Возвращая сам birthDate, мы рискуем отдать ссылку на внутренний объект,
    // который могут изменить снаружи. Нужно снова копировать.
    public Date getBirthDate() {
        return new Date(birthDate.getTime());
    }
}
```
- **Входные данные**: в конструкторе мы копируем объект `Date`, чтобы в `Person` не попала потенциально изменяемая ссылка.  
- **Возврат данных**: при геттере мы снова **возвращаем копию**, чтобы никто не смог изменить исходный `Date` внутри `Person`.

Если у поля более сложный тип (например, `List` или `Map`), действуют те же принципы:  
- Использовать **неизменяемые коллекции** (например, `Collections.unmodifiableList(...)`) или  
- Создавать **защитные копии** при чтении/записи.

---

## Пример полноценного неизменяемого класса

```java
import java.util.Collections;
import java.util.List;

public final class ImmutableStudent {
    private final String name;
    private final int age;
    private final List<String> subjects;

    public ImmutableStudent(String name, int age, List<String> subjects) {
        this.name = name;
        this.age = age;
        // Чтобы класс остался неизменяемым,
        // копируем список и делаем его неизменяемым
        this.subjects = Collections.unmodifiableList(subjects);
    }

    public String getName() {
        return name;
    }

    public int getAge() {
        return age;
    }

    public List<String> getSubjects() {
        return subjects;
    }
}
```

Обратите внимание на следующие детали:
1. **final** класс (необязательно, но желательно) — чтобы от него нельзя было унаследоваться и “сломать” неизменяемость.  
2. **final** поля.  
3. Нет setter-методов.  
4. Принимаем `List<String>` и делаем `Collections.unmodifiableList` для защиты от изменений.  
5. При возврате `getSubjects()` отдаём ту же ссылку, но она неизменяемая. Если в конструктор передали изменяемый список, все изменения до вызова конструктора уже прошли, а после — класс защищён.

---

## Выгоды использования неизменяемых объектов

1. **Безопасность многопоточности**: не нужно синхронизировать доступ к immutable-объекту. Разные потоки могут свободно его использовать.  
2. **Упрощение логики**: если объект не меняется, то при отладке проще найти, где он был создан и каким образом.  
3. **Меньше ошибок**: благодаря отсутствию побочных эффектов, код становится более предсказуемым.  
4. **Возможность кэшировать и переиспользовать**: один и тот же неизменяемый объект можно хранить в статических полях, отдавать при каждом запросе и не бояться, что кто-то его изменит.

---

## Заключение

Неизменяемые объекты — важный инструмент в арсенале Java-разработчика, позволяющий:
- Упростить многопоточный код (отпадает необходимость тонко настраивать синхронизацию).  
- Избежать непредсказуемого поведения при изменении состояния (особенно в больших и сложных проектах).  
- Придерживаться принципов функционального стиля (отсутствие сайд-эффектов).  

Основное правило: **один раз создали — не изменяем**. Если требуется «изменить», — создаём **новый** экземпляр на основе предыдущего состояния. Такая концепция хоть и требует больше памяти (новые объекты вместо модификации старого), но во многих случаях оправдывает себя своей надёжностью и безопасностью.

# <a name="обработка-данных-в-очередях"></a>Обработка данных в очередях

Современные системы, особенно ориентированные на высокую пропускную способность и распределённую архитектуру (микросервисы, брокеры сообщений, фреймворки по принципу «producer-consumer»), широко используют очереди для буферизации и асинхронной обработки данных. Ниже описаны основные параметры и дисциплины обслуживания очередей, вопросы балансировки нагрузки, а также конфликты требований при проектировании очередей.

---

## Параметры очереди

### 1. Пропускная способность (Throughput)
- **Определение**: количество сообщений (заданий), обрабатываемых в единицу времени.  
- **Факторы**:
  - Производительность исполнительных «консумеров».  
  - Пропускная способность сетевого канала (если очередь распределённая).  
  - Производительность дисковой подсистемы (при сохранении сообщений на диск).  

### 2. Время ожидания (Latency)
- **Определение**: время от момента помещения сообщения (задачи) в очередь до начала обработки (или до завершения обработки).  
- **Причины роста задержки**:
  - «Узкие места» (bottlenecks) в обработке.  
  - Малое количество потребителей или их низкая производительность.  
  - Слишком большой наплыв сообщений.

### 3. Максимальный размер (Capacity / Queue Length)
- **Описание**: лимит на количество хранимых сообщений в очереди.  
- **Варианты**:
  - **Неограниченная** (упирается в физическую память/диск).  
  - **Фиксированная** (например, `BlockingQueue` с заданным размером).  
- **Следствие**: если очередь заполнена до максимума, новые сообщения могут отклоняться (throw exception) или блокировать производителей до освобождения места.

### 4. Надёжность (Reliability)
- **Описание**: гарантии сохранности сообщений (чтобы они не терялись при сбоях).  
- **Подходы**:
  - Журналирование (journaling) на диск.  
  - Репликация в нескольких узлах.  
  - Атомарные транзакции.  

---

## Дисциплины обслуживания

### 1. FIFO (First In, First Out)
- **Сущность**: задания обрабатываются в порядке поступления.  
- **Применение**: наиболее распространено, так как справедливо по отношению ко всем сообщениям.

### 2. LIFO (Last In, First Out)
- **Сущность**: последнее пришедшее задание обрабатывается первым.  
- **Применение**: редко, в специфических сценариях (например, реализация стека).

### 3. Приоритетная очередь (Priority Queue)
- **Сущность**: каждое сообщение имеет приоритет; сообщения с более высоким приоритетом обрабатываются раньше.  
- **Применение**: системы реального времени, критичные задачи, VIP-трафик.  
- **Особенность**: требует дополнительной логики управления приоритетами.

### 4. Смешанные стратегии
- **Описание**: комбинации FIFO и приоритетов. Например, внутри приоритетных классов всё равно выполняется FIFO.  
- **Пример**: несколько уровней приоритетов, а внутри каждого — обычная очередь.

---

## Балансировка нагрузки

### 1. Горизонтальное масштабирование (Horizontal Scaling)
- **Описание**: добавление новых потребителей (consumer) в систему, чтобы обрабатывать сообщения параллельно.  
- **Особенность**: очередь обычно распределённая (clustered), либо у каждого потребителя своя локальная часть очереди.  

### 2. Шардирование очередей (Sharding / Partitioning)
- **Описание**: большая очередь разбивается на несколько «шард» (партиций), и каждая партиция обрабатывается своей группой потребителей.  
- **Плюсы**:
  - Более высокая пропускная способность.  
  - Лучшая масштабируемость.  
- **Минусы**:
  - Может быть сложнее гарантировать строгий порядок (FIFO) по всей системе, если записи распределены по нескольким партициям.

### 3. Управление скоростью (Rate Limiting)
- **Описание**: ограничение числа поступающих сообщений или скорости обработки, чтобы не перегружать сервисы.  
- **Реализация**: токен-бак (token bucket), leaky bucket и т.п.

---

## Управление “плохими” задачами

### 1. Повторные попытки (Retries) и отложенные очереди (Dead Letter Queue)
- **Повторные попытки**: если задача не обрабатывается из-за ошибки, можно вернуть её в очередь или поместить в отдельную очередь для повторной обработки.  
- **Dead Letter Queue (DLQ)**: окончательный “захоронитель” сообщений, не обработанных корректно после нескольких повторов. Служит для ручной диагностики или альтернативной маршрутизации.

### 2. Ограничение времени выполнения (Time-to-live, TTL)
- **Описание**: у каждого сообщения может быть срок жизни (TTL). Если оно не обработано за это время, оно либо отбрасывается, либо переносится в DLQ.  
- **Применение**: полезно для данных, которые быстро теряют актуальность.

### 3. “Карантин” для проблемных сообщений
- **Описание**: если сообщение вызывает повторяющиеся ошибки, отправлять его в специальную очередь для ручного разбора, чтобы не блокировать поток обработки.

---

## Параметры обработки очередей и мониторинг состояния

### 1. Мониторинг ключевых метрик
- **Очередь**:
  - Текущая длина (сколько сообщений в очереди).  
  - Средняя / максимальная задержка (time in queue).  
- **Потребители**:
  - Количество активных работников (workers).  
  - Количество обработанных сообщений в единицу времени.  
  - Уровень ошибок при обработке.

### 2. Алёрты и оповещения
- **Описание**: системы наблюдения (Prometheus, Grafana, CloudWatch) отслеживают метрики и при превышении пороговых значений (длина очереди, время ожидания и т.д.) посылают уведомления (email, Slack, PagerDuty).

### 3. Автомасштабирование (Auto-scaling)
- **Идея**: если длина очереди растёт и начинает превышать заданный уровень, автоматически запускать больше потребителей (или поднимать новые инстансы). Когда очередь опустела, сокращать лишние ресурсы.

---

## Конфликт требований к очередям

При проектировании системы с очередями часто возникают противоречия:

1. **Высокая пропускная способность vs. Низкая задержка (throughput vs. latency)**
   - Если мы хотим обрабатывать как можно больше сообщений в секунду, иногда приходим к “пакетной” обработке, что может увеличить время ожидания.  
   - Если же требуется минимальная задержка для каждого сообщения, снижается эффективность пакетной обработки.

2. **Надёжность (полная сохранность) vs. Скорость**
   - Сохранение каждого сообщения на диск или репликация по сети даёт высокую надёжность, но замедляет обработку.  
   - Быстрая in-memory очередь повышает риск потери данных при сбоях.

3. **Гарантии порядка (strict FIFO) vs. Горизонтальное масштабирование**
   - Для строгого порядка нужно обрабатывать сообщения последовательно. Это часто не сочетается с параллелизмом.  
   - Распараллеливание (шардирование) усложняет сохранение глобального порядка.

4. **Простота потребителей vs. Управление “плохими” задачами**
   - Если потребители не умеют обрабатывать ошибки и всё время «зависают» на проблемных сообщениях, очередь блокируется.  
   - Для стабильности системы нужно сложное управление повторными попытками, DLQ, мониторинг, что усложняет архитектуру.

---

# Итог

Обработка данных в очередях — фундаментальный механизм в современных распределённых системах. Правильное проектирование таких систем требует учёта множества параметров: пропускная способность, задержка, надёжность, мониторинг, масштабирование и т.д. Также необходимо прорабатывать политику управления “плохими” задачами, дисциплины обслуживания (FIFO, приоритеты) и учитывать возможные конфликты требований (быстрота vs. надёжность, пакетная обработка vs. минимизация задержек и пр.).

Выбор конкретной реализации (RabbitMQ, Apache Kafka, JMS, SQS и прочие) и детальная конфигурация зависят от конкретных бизнес-задач: нужны ли строгие гарантии доставки, важен ли порядок, какова нагрузка и т.д. Грамотно настроенные очереди позволяют добиться высокой устойчивости и эластичности системы, а их мониторинг гарантирует быстроту реакции на любые аномалии в работе.

# <a name="синхронизированные-алгоритмы"></a>Синхронизированные алгоритмы

Ниже приводится обзор уровней не/блокирующих алгоритмов (obstruction-free, lock-free, wait-free), а также подходов к реализации коллекций (грубая, тонкая, оптимистичная, ленивая, неблокирующая). В завершение кратко рассмотрим принцип построения «очереди с корзинами» (basket queue).

---

## Уровни алгоритмов: obstruction-free, lock-free, wait-free

### Obstruction-free
Алгоритм считается obstruction-free, если при отсутствии конфликтов (то есть когда поток выполняется «в одиночестве», без помех со стороны других потоков) он гарантированно завершит операцию за конечное время. При появлении конфликтов и вмешательстве других потоков алгоритм может прерываться и начинать операцию заново.

### Lock-free
Lock-free гарантирует, что система (по крайней мере один поток) будет совершать прогресс за конечное число шагов, даже если несколько потоков одновременно обращаются к ресурсу и могут мешать друг другу. Сам поток, который находится в конфликте, может неоднократно повторять операцию (CAS не прошёл), но всегда есть вероятность, что она у него получится, либо получится у другого потока.

### Wait-free
Wait-free обеспечивает гарантированный прогресс **каждого** потока за конечное число шагов, независимо от деятельности других потоков. Это наиболее «сильная» гарантия не/блокирующей синхронизации. В реальных структурах данных (особенно сложных) встретить полный wait-free сложнее всего.

---

## Реализация коллекций: грубая, тонкая, оптимистичная, ленивая, неблокирующая

### Грубая (coarse-grained)
Коллекция использует одну большую блокировку (например, один `synchronized` на всю структуру). Каждый вызов любого метода (добавление, удаление, поиск и т. д.) блокирует всю коллекцию и освобождает её после завершения операции. Таким образом, операции «по очереди» получают доступ к структуре.

### Тонкая (fine-grained)
Коллекция делится на части (сегменты, узлы, блоки), и каждая часть блокируется отдельно (собственный `Lock` или `synchronized`). Если поток работает с определённым сегментом, остальные сегменты остаются открыты для других потоков. Это повышает степень параллелизма. Пример — сегментированная мапа, где каждая группа корзин (bucket) имеет собственную блокировку.

### Оптимистичная (optimistic)
Предполагает, что конфликты в структуре редки. Поток читает или готовит данные, потом проверяет, не изменилась ли структура за время чтения (например, с помощью CAS или сравнения версионного штампа). Если изменений не было, фиксирует изменения. Если кто-то уже успел модифицировать структуру, операция откатывается и повторяется. Такое «предположительно без блокировок» чтение ускоряет обработку, когда реальных конфликтов мало.

### Ленивая (lazy)
Некоторые операции (обычно удаление) откладывают освобождение ресурсов. Например, в списке удаляемый элемент не сразу исключается физически, а лишь помечается как «неактуальный» (marked = true). При дальнейшем обходе структуры «получившие пометку» элементы окончательно удаляются. Такой подход сокращает время, затрачиваемое непосредственно в операции удаления.

### Неблокирующая (non-blocking)
Для управления структурой данных (очереди, стеки, списки) применяются атомарные операции (CAS), без использования стандартных `Lock`/`synchronized`. Поток читает текущее состояние (например, указатель на голову списка), вычисляет новое и пытается записать его обратно через CAS. Если другие потоки успели изменить состояние, CAS не проходит, и операция повторяется. Так достигается lock-free (а иногда и wait-free) работа со структурой.

---

## Коллекции на AtomicReference

Многие неблокирующие структуры данных (стек, очередь, список) могут быть построены с помощью `AtomicReference` для хранения следующего узла или головного указателя. При вставке (или удалении) поток формирует новое состояние и делает CAS над текущим указателем. Если CAS прошёл, операция успешно завершена, если нет — поток снова читает актуальное состояние и повторяет попытку.

```java
class Node<E> {
    E value;
    AtomicReference<Node<E>> next;
}

class LockFreeStack<E> {
    private AtomicReference<Node<E>> head = new AtomicReference<>(null);

    public void push(E val) {
        Node<E> newNode = new Node<>(val);
        Node<E> oldHead;
        do {
            oldHead = head.get();
            newNode.next.set(oldHead);
        } while (!head.compareAndSet(oldHead, newNode));
    }

    public E pop() {
        Node<E> oldHead;
        Node<E> newHead;
        do {
            oldHead = head.get();
            if (oldHead == null) {
                return null; // stack is empty
            }
            newHead = oldHead.next.get();
        } while (!head.compareAndSet(oldHead, newHead));
        return oldHead.value;
    }
}
```

---

## Очередь с корзинами (basket queue)

Очередь делится на небольшие «корзины» (baskets). Каждая корзина может сама быть реализована как небольшая lock-free структура (например, на атомарных ссылках). При добавлении (enqueue) поток выбирает корзину, в которой есть место (по индексу, по round-robin, по хешу) и выполняет вставку. Если корзина заполнена, поток переключается на другую. При извлечении (dequeue) поток ищет корзину, где есть элементы, и забирает один. Благодаря распределению по корзинам в систему вводится возможность параллельного добавления и извлечения нескольких элементов разными потоками без централизации на одном указателе.

---

# Итог

- **Obstruction-free** гарантирует прогресс при «одиночном» исполнении.  
- **Lock-free** обеспечивает глобальный прогресс, исключая ситуацию, когда система “застывает” из-за одного проблемного потока.  
- **Wait-free** гарантирует прогресс всем потокам за конечное время.  

Коллекции могут быть реализованы с разной степенью гранулярности синхронизации: грубая (одна блокировка), тонкая (блокировки на сегментах), оптимистичная (проверка изменений в конце), ленивая (отложенное освобождение элементов) и неблокирующая (CAS-операции). Применение `AtomicReference` лежит в основе lock-free и wait-free структур, а «очередь с корзинами» является одним из вариантов улучшения пропускной способности и параллелизма за счёт разбиения данных на независимые сегменты.

# <a name="взаимное-исключение-в-распределённых-системах"></a>Взаимное исключение в распределённых системах

Взаимное исключение (mutual exclusion) — это механизм, который гарантирует, что общий ресурс не будет одновременно использоваться несколькими процессами. В классической (локальной) среде эту задачу решают посредством блокировок, семафоров и т.д. В **распределённых системах** реализация взаимного исключения усложняется из-за необходимости обмена сообщениями по сети, отсутствия общего физического адресного пространства и непредсказуемостей (задержки, сбои узлов, сетевые разделы).

---

## Сложность реализации в распределённых системах

1. **Нет общего памяти и единого временного штампа**  
   Взаимодействие между процессами идёт через обмен сообщениями. Нужно строить протоколы, учитывающие возможные сетевые задержки и отсутствие глобальных синхронизированных часов.

2. **Сбои и непредсказуемое сетевое поведение**  
   Участники могут «отвалиться» или «зависнуть», при этом не всегда очевидно, жив ли узел или просто временно потерял связь. Требуются механизмы обнаружения отказов (failure detection) и повторных запросов.

3. **Необходимость выбора координатора или распределённой договорённости**  
   При централизованных решениях узел-координатор управляет доступом к ресурсу. При его сбое нужно быстро выбрать нового координатора. В децентрализованных решениях важен консенсус между всеми узлами.

4. **Опасность взаимоблокировок (deadlock) или «голодания» (starvation)**  
   Требуется аккуратная логика протокола, чтобы не возникало циклов ожидания и чтобы каждый процесс в конечном итоге получал доступ к ресурсу.

---

## Задача обедающих философов

В контексте **распределённых систем** задачу обедающих философов можно трактовать как ситуацию, где несколько распределённых процессов (философов) хотят получить доступ к разделяемым ресурсам (вилки) для выполнения критической секции (приёма пищи). Каждый философ:
1. Запрашивает доступ к вилкам (ресурсам).
2. Если вилки свободны — начинает «есть» (заходит в критическую секцию).
3. Освобождает вилки по окончании.

В распределённом варианте «вилки» могут быть физически разнесены, а философы — это удалённые узлы. Протокол должен:
- Исключать одновременный доступ к одной вилке несколькими философами.  
- Правильно обрабатывать ситуации, когда узлы посылают запросы на ресурсы по сети.

Этот классический пример демонстрирует потенциальные проблемы: тупики, голодание, проблемы с координацией.

---

## Централизованные алгоритмы

### 1. Алгоритм с координатором (Central server)
Один узел объявляется координатором. Любой процесс, желающий войти в критическую секцию, отправляет ему запрос:
1. Координатор, получив запрос на ресурс, проверяет, свободен ли он.
2. Если ресурс свободен, даёт «разрешение» на вход в критическую секцию, а ресурс отмечается занятым.
3. Если ресурс занят, запрос ставится в очередь. Координатор, освободив ресурс, разрешает доступ следующему по очереди.
4. По завершении работы в критической секции процесс посылает координатору уведомление об освобождении ресурса.

### 2. Изменение координатора при его сбое
Если координатор выходит из строя, надо выбрать нового. Примером может служить алгоритм «bully» или «Ring Election Algorithm». После выбора нового координатора запросы на доступ к ресурсу направляют уже ему.

В результате все процессы знают «центр», через который проходят все запросы на взаимное исключение.

---

## Децентрализованные алгоритмы

### 1. Алгоритм на основе распределённого согласования (Ricart–Agrawala)
Каждый процесс, желая войти в критическую секцию, рассылает запрос всем другим процессам:
1. Запрос содержит логический временной штамп (Lamport timestamp), чтобы упорядочить очереди.
2. Получая запрос, процесс принимает решение, можно ли немедленно ответить «ОК» (если сам не претендует на ресурс или у него запрос с более поздним штампом).  
3. Процесс входит в критическую секцию, когда получил «ОК» от всех.  
4. По выходе из критической секции рассылает уведомления, позволяющие другим процессам двигаться дальше.

Здесь нет единого координатора, порядок поддерживается логическими часами и взаимными подтверждениями.

### 2. Алгоритм распределённого дерева
Существует структура-дерево (или логическая кольцевая топология). Узел, желая войти в критическую секцию, отправляет запрос соседу, тот — своему соседу и т.д., пока запрос не достигнет владельца ресурса. После освобождения ресурс передаётся следующему по дереву. Так достигается децентрализация: нет центральной точки, в которой бы концентрировались все запросы. При сбоях таких алгоритмов важно уметь перестраивать дерево или кольцо.

---

# Итог

Реализация взаимного исключения в распределённой среде требует специальных алгоритмов, учитывающих отсутствие общей памяти, возможные сетевые задержки, сбои узлов и необходимость достижения согласия между независимыми процессами. Централизованные решения используют единый узел-координатор, который управляет ресурсом, а децентрализованные распределяют логику по всем участникам (через взаимные обмены сообщениями и логику упорядочения). Классическая задача обедающих философов хорошо иллюстрирует проблемы, с которыми сталкиваются процессы, конкурирующие за распределённые ресурсы.

# <a name="асинхронная-разработка"></a>Асинхронная разработка

Асинхронная модель работы позволяет выполнять операции, не блокируя основной поток. Если операция требует долгого ожидания (сетевой запрос, чтение из файловой системы, обращение к базе данных), поток не «замораживается» на всё время ожидания, а может обрабатывать другие задачи. Ниже перечислены основные аспекты асинхронной разработки в контексте Java: проблемы блокирующих алгоритмов, использование колбэков, `CompletableFuture` и реактивное программирование.

---

## Проблемы блокирующих алгоритмов

### Блокировка потока при долгих операциях
Когда поток выполняет запрос к удалённому сервису, базе данных или файловой системе в синхронном (блокирующем) режиме, он вынужден ждать ответа. Это ведёт к тому, что поток простаивает, в то время как можно было бы заняться другими задачами.

### Ограничение числа потоков
Всякий поток — это ограниченный ресурс. Если приложение для каждого ожидания порождает отдельный поток, возрастает нагрузка на планировщик ОС и растут накладные расходы (контекстные переключения, память под стеки). При очень большом числе одновременных блокировок производительность резко падает.

### Сложность масштабирования
В системах с высокими нагрузками блокирующие вызовы затрудняют масштабирование: можно добавить больше аппаратных ресурсов (CPU, оперативной памяти), но если основной поток постоянно ждёт, рост производительности не проявится.

---

## Callback

### Суть колбэков
Колбэки (обратные вызовы) — это функция (или метод), которая передаётся куда-то (например, в асинхронный метод) и вызывается при завершении операции. Вместо того, чтобы блокироваться, основной поток назначает колбэк и продолжает работу. По окончании фоновой (долгой) операции колбэк уведомляет, что данные готовы.

Пример (обобщённый псевдокод):
```
void asyncOperation(Callback callback) {
    // запускаем асинхронную задачу
    // когда закончится, вызываем:
    callback.onComplete(result);
}
```

### Применение в Java
В Java колбэки часто используются при работе с асинхронными фреймворками (Netty, Vert.x), а также при работе с GUI (например, в Swing).

### Проблема «адского дерева колбэков»
При сложных сценариях (выполнить задачу А, затем задачу B, затем задачу C…) колбэки могут вкладываться друг в друга, образуя «пирамиду» громоздкого кода, которую трудно читать и поддерживать. Для решения в Java используют `CompletableFuture` или реактивные подходы, где можно связывать несколько асинхронных операций линейно или через композицию.

---

## CompletableFuture и thenApplyAsync()

### Основные возможности
`CompletableFuture` — класс из Java, позволяющий работать с асинхронными задачами без глубоких «вложенных» колбэков. Можно запустить задачу, вернув `CompletableFuture`, и затем «повесить» на неё цепочку зависимых операций.

Пример (упрощённый):
```java
CompletableFuture.supplyAsync(() -> {
    // долгий код, например запрос к базе
    return "data";
}).thenApplyAsync(data -> {
    // ещё одна асинхронная обработка
    return data.toUpperCase();
}).thenAcceptAsync(result -> {
    // завершающее действие
    System.out.println("Result: " + result);
});
```

### Управление потоками
- `supplyAsync()` использует пул потоков (ForkJoinPool или кастомный Executor).
- `thenApplyAsync()`, `thenAcceptAsync()`, `thenComposeAsync()` и другие методы позволяют указать, что следующий колбэк тоже будет выполняться в пуле потоков асинхронно.
- При необходимости можно передавать свой `Executor`, чтобы контролировать, где именно исполняются дальнейшие этапы.

### Сцепка нескольких асинхронных вызовов
Можно объединять несколько `CompletableFuture`:
- `thenCompose(...)` для последовательной зависимости (результат одной задачи передаётся в следующую).
- `thenCombine(...)` для параллельных задач, чей результат объединяется.

---

## Реактивное программирование

### Принцип работы
Реактивное программирование базируется на потоке данных и концепции «наблюдатель» (observer) или «подписчик» (subscriber). Код выражается в виде цепочек операторов, где каждый оператор может преобразовывать, фильтровать или агрегировать события, поступающие асинхронно.

### Основные понятия
- **Observable/Flux/Flowable**: источник данных (стрим событий).
- **Observer/Subscriber**: потребитель данных (подписывается на события).
- **Operators**: промежуточные преобразования (map, filter, reduce и т.д.).

### Реализации в Java
- **Project Reactor** (используется в Spring WebFlux).
- **RxJava** (пакет операторов, вдохновлённый Reactive Extensions).
- **Mutiny, Akka Streams**, и др. в экосистеме Java/Scala.

### Пример (на Project Reactor)
```java
Flux.just("alpha", "beta", "gamma")
    .map(String::toUpperCase)
    .filter(str -> str.startsWith("A"))
    .subscribe(item -> System.out.println("Got: " + item));
```
Здесь нет прямых блокировок: «поток» данных проходит через цепочку операторов, и при появлении нового элемента вызывается `subscribe`.

---

# Итог

В асинхронной разработке важно уходить от блокирующих вызовов, чтобы не простаивали потоки при долгих операциях. Для этого используются:
- **Callback**: классический способ зарегистрировать обратный вызов, который сработает по завершении операции.
- **CompletableFuture**: даёт удобные методы (`thenApplyAsync()`, `thenAcceptAsync()`) для формирования последовательностей асинхронных действий.
- **Реактивное программирование**: строит реактивные «потоки» данных (Flux, Mono, Flowable) и позволяет работать с асинхронными событиями в виде конвейеров операторов, упрощая управление сложными асинхронными сценариями.