# Оглавление

1. [Лекция 1](#лекция-1)
2. [Лекция 2](#лекция-2)
3. [Лекция 3](#лекция-3)
4. [Лекция 4](#лекция-4)
5. [Лекция 5](#лекция-5)
6. [Лекция 6](#лекция-6)
7. [Лекция 7](#лекция-7)
8. [Семафоры](#сем)
9. [Обработка данных в очередях](#обработка-данных-в-очередях)
10. [Синхронизированные алгоритмы](#синхронизированные-алгоритмы)
11. [Взаимное исключение в распределённых системах](#взаимное-исключение-в-распределённых-системах)
12. [Асинхронная разработка](#асинхронная-разработка)
13. [Ссылки](#ссылки)
---

# <a name="лекция-1"></a>Лекция 1

## Задача, стоящая перед нами

Взять Maven или Gradle, сделать простой проект, делающий что-то и тесты к нему. Задача должна быть вычислительно сложной. Время работы от 3 до 10 сек. Примеры: вычисление площади под графиком

**Дополнение**:  
*Для таких проектов часто удобно использовать плагины для автоматического тестирования и профилирования — например, Surefire и Jacoco в Maven, чтобы проверить корректность и производительность.*

---

## Параллельные вычисления и многопоточное программирование

**Параллельные вычисления** позволяют выполнять несколько задач одновременно, что сокращает общее время выполнения программы. **Многопоточное программирование** — это подход, при котором в рамках одного процесса создаются несколько потоков для выполнения различных задач.

Преимущества многопоточного программирования:
- Улучшение производительности на многопроцессорных системах.
- Реализация более отзывчивых программ (например, GUI).
- Эффективное использование ресурсов процессора.

Основные вызовы:
- Потокобезопасность.
- Сложность отладки.
- Переключение контекста, которое может увеличивать накладные расходы.

**Дополнение**:  
*В Java для безопасного доступа к разделяемым ресурсам используют синхронизированные блоки, объекты `Lock` (из пакета `java.util.concurrent.locks`), а также атомарные переменные (`AtomicInteger`, `AtomicLong` и др.).*

---

## Архитектура параллельных вычислительных систем

Современные вычислительные системы имеют архитектуры, оптимизированные для параллельных вычислений:
1. **Многоядерные процессоры**:
   - Несколько ядер в одном процессоре.
   - Поддерживают аппаратную многопоточность.
2. **Системы с разделяемой памятью**:
   - Общая память для всех процессоров.
   - Требуется синхронизация доступа.
3. **Распределенные системы**:
   - Несколько узлов соединены сетью.
   - Каждый узел имеет свою локальную память.
4. **Графические процессоры (GPU)**:
   - Оптимизированы для массово параллельных вычислений.
   - Используются в машинном обучении и компьютерной графике.
5. **Кластерные системы**:
   - Объединение множества серверов для работы как одного суперкомпьютера.
   - Используют MPI или другие протоколы для связи между узлами.

Архитектура выбирается в зависимости от типа задач и уровня параллелизма, который требуется достичь.

**Дополнение**:  
*Для некоторых типов задач (например, машинное обучение) удобнее использовать гибридные архитектуры, где сочетаются CPU и GPU (так называемые heterogeneous computing).*

---

# <a name="лекция-2"></a>Лекция 2

## Цель распараллеливания

Основная цель распараллеливания — это минимизация времени выполнения задач за счет их распределения на несколько процессоров или ядер. Это достигается путем:
- Разделения задач на независимые части.
- Одновременного выполнения нескольких частей задачи.

**Дополнение**:  
*При проектировании параллельного алгоритма важно учесть масштабируемость: как быстро увеличивается производительность при добавлении новых ядер/процессоров.*

---

## Минимум времени выполнения работ

Эффективное распараллеливание позволяет:
- Уменьшить общее время выполнения программы.
- Снизить задержки при выполнении долгих операций.
- Увеличить пропускную способность системы.

---
 - Статическое планирование - заранее продумываем план и реализацию.
 - Динамическое планирование - продумываем в процессе работы системы.
---

**Дополнение**:  
*При динамическом планировании можно использовать планировщики (schedulers) или средства типа «work-stealing» (в `ForkJoinPool`), чтобы равномернее распределять нагрузку.*

---

## Классификация ЭВМ

Классификация Флинна, основанная на том, как устроена в компьютере обработка данных. Согласно этой классификации все компьютеры (вычислительные комплексы) можно разделить на четыре класса - компьютеры с архитектурой:

- SISD (Single Instruction stream - Single Data stream) - одиночный поток команд - одиночный поток данных. К этому классу относятся обычные "последовательные" компьютеры с фон-Неймановской архитектурой, когда команды программы выполняются последовательно, обрабатывая очередной элемент данных.
- SIMD (Single Instruction stream - Multiple Data stream) - одиночный поток команд - множественный поток данных. К этому типу относятся компьютеры с векторными и матричными процессорами.
- MISD (Multiple Instruction stream - Single Data stream) - множественный поток команд - одиночный поток данных. К этому типу можно отнести компьютеры с конвейерным типом обработки данных. Однако, многие полагают, что такие компьютеры следует относить к первому типу, а компьютеры класса MISD пока не созданы.
- MIMD (Multiple Instruction stream - Multiple Data stream) - множественный поток команд - множественный поток данных. Класс MIMD чрезвычайно широк и в настоящее время в него попадают многие компьютеры достаточно разной архитектуры. Поэтому предлагаются другие классификации, позволяющие более точно классифицировать компьютеры, входящие в класс MIMD.

**Дополнение**:  
*В реальных системах MIMD часто сочетается с векторными инструкциями (SIMD), поэтому процессор может быть одновременно и «MIMD+SIMD».*

---

## Коэффициент полезной загрузки

Коэффициент полезной загрузки вычислительной системы показывает, насколько эффективно используются ресурсы. Высокий коэффициент достигается при равномерном распределении задач между всеми доступными ядрами/процессорами.

![Граф переходов](image.png)

Критический путь 1 -> 5 -> 2 -> 3 -> 4.

$T_i$ - время выполнения одной задачи. $T_{oi} = \sum_{i=0}^{n} T_i$  - общее время выполнения для одного процесора

$T_{o1} = 5$, $T_{o2} = 4$

$\dfrac{T_{o1}}{T_{o2}} = 1,25$ - Ускорение

$K_з = \dfrac{4 + 1}{4 * 2} = \dfrac{5}{8} = 0, 625$ - коэффициент загрузки

**Дополнение**:  
*Иногда полезно анализировать граф зависимостей (DAG) задач, чтобы максимально эффективно распараллелить вычисления и увеличить коэффициент полезной загрузки.*

---

## Два уровня распараллеливания: по данным и по управлению

1. **Распараллеливание по данным**:
   - Задача разбивается на подзадачи, каждая из которых работает с отдельным набором данных.
   - Примеры: обработка массивов, параллельные вычисления в графике.
2. **Распараллеливание по управлению**:
   - Задача разбивается на подзадачи, каждая из которых выполняет свою логику.
   - Примеры: параллельная обработка запросов, многопоточная загрузка данных.

Эти два подхода могут сочетаться для достижения максимальной производительности.

**Дополнение**:  
*Часто распараллеливание по данным применяется при аналитических операциях над большими массивами (Big Data), а по управлению — в серверных приложениях, обрабатывающих множество независимых запросов.*

---

**Класс Thread** - поток в Java. Интерфейс `Runnable` - имеет метод `run()`.

**Thread** - получает объект `Runnable` и вызывает метод `run()`. Поток завершает работу, когда завершает работу метод `run()`.

Метод `start()` создает поток в ОС

**Дополнение**:  
*Создавать потоки напрямую удобно для простых сценариев. Для более сложных задач зачастую лучше использовать «thread pools», чтобы избежать постоянного создания новых потоков.*

---

# <a name="лекция-3"></a>Лекция 3

## Процессы: владелец ресурсов

**Процесс** в ОС — это выполняющаяся программа, обладающая собственным адресным пространством, открытыми файлами (дескрипторами), сетевыми соединениями и другими системными ресурсами. Процесс изолирован от других процессов для безопасности и стабильности системы.  

- В большинстве систем у каждого процесса есть **уникальный идентификатор процесса (PID)**.  
- Процесс может состоять из одного или нескольких **потоков**.  
- В отличие от потоков, процессы взаимодействуют друг с другом через механизмы межпроцессного взаимодействия (IPC) — сокеты, каналы, очереди сообщений и т.д.

Вся память, вычделенная во время работы процесса, принадлежит этому процессу

**Дополнение**:  
*В некоторых ОС есть механизмы «разделяемой памяти» (shared memory), позволяющие нескольким процессам совместно использовать определённые области памяти для более быстрого взаимодействия.*

---

## Потоки и стратегия управления ЦПУ

**Поток** (thread) — это "легковесный" поток управления внутри процесса. Все потоки одного процесса разделяют общее адресное пространство и общие ресурсы. В контексте Java потоки создаются с помощью класса `Thread` или через механизмы более высокоуровневой абстракции (например, `ExecutorService`, `ForkJoinPool` и т.д.).

Потокам выделяется процессорное время и они имеею только его.

**Дополнение**:  
*ОС обычно использует приоритеты потоков и алгоритмы планирования (Round Robin, Priority Scheduling и др.) для распределения процессорного времени.*

---

## Закон Мура

Закон Мура (исторически сформулированный Горденом Муром) предсказывал экспоненциальный рост количества транзисторов на кристалле примерно каждые 18-24 месяца. Однако в последнее время упираемся в физические ограничения, рост стал замедляться, что приводит к стратегии увеличения числа ядер, а не только частоты процессора. Именно поэтому многопоточность и распараллеливание приобретают все большее значение.

**Дополнение**:  
*Новые тенденции включают также трёхмерную компоновку полупроводников (3D-stacking) и специализацию чипов (ASIC, FPGA) для определённых типов задач.*

---

## Стратегии управления памятью

### Виртуальная память

Виртуальная память — это механизм, позволяющий создать для каждого процесса **абстракцию** непрерывного адресного пространства. Физическая память (ОЗУ) обычно меньше совокупного объема виртуальной памяти всех процессов, поэтому ОС может временно выгружать (swapping/paging) неиспользуемые части (страницы) памяти на диск (в файл подкачки) и подгружать их при необходимости обратно.

**Дополнение**:  
*Чрезмерная активность подкачки (thrashing) может существенно замедлить систему, поэтому важно следить за объёмом используемой памяти.*

---

### Physical Address Extension (PAE)

PAE (Physical Address Extension) — технология, позволяющая 32-битным процессорам адресовать больше 4 ГБ оперативной памяти (до 64 ГБ). В современных 64-битных системах поддержка больших объёмов оперативной памяти уже встроена на уровне архитектуры.

**Дополнение**:  
*При работе со старыми системами иногда приходится вручную включать поддержку PAE в настройках ОС (например, в некоторых версиях Linux).*

---

### Множество потоков

Многопоточность позволяет одной программе более эффективно использовать ресурсы многоядерных/многопроцессорных систем. Некоторые преимущества многопоточности:

- Параллельное выполнение независимых задач.
- Более быстрая реакция GUI-приложения (например, выделение фоновых потоков для долгих операций).
- Упрощение структуры программы, когда разные задачи ведут себя как отдельные потоки (например, серверные приложения).

**Дополнение**:  
*Однако следует учитывать гонки данных (race conditions) и мертвые блокировки (deadlocks), и применять правильные механизмы синхронизации.*

---

Daemon thread (Демон-потоки) - потоки в Java, не учавствующие в завершении программы. `setDaemon()` - делает поток фоновым.

Механизм прерываний реализован с использованием внутреннего флага, известного как *статус прерывания* . Вызов `Thread.interrupt` устанавливает этот флаг. Когда поток проверяет прерывание, вызывая статический метод `Thread.interrupted`, статус прерывания очищается. Нестатический `isInterrupted` метод, который используется одним потоком для запроса статуса прерывания другого, не изменяет флаг статуса прерывания.

По соглашению, любой метод, который завершается, выдавая , `InterruptedException` очищает статус прерывания, когда он это делает. Однако всегда возможно, что статус прерывания будет немедленно установлен снова другим потоком, вызывающим `interrupt`.

**Дополнение**:  
*При написании многопоточного кода всегда следует корректно обрабатывать прерывания, особенно в долгих циклах или блокирующих операциях (I/O, `sleep()`, `wait()`).*

Ниже приведён ваш исходный текст с небольшими **вставками** (курсивом), которые расширяют тему, не меняя ваши формулировки и структуру.

---

# <a name="лекция-4"></a>Лекция 4

## Циклы: инициализация, тело, обработка результатов. Тело без побочных эффектов. Рекурсия

Любой цикл обычно состоит из:
- Инициализации (подготовка параметров, переменных и т. п.),
- Тела цикла (основные действия),
- Обработки результатов (суммирование частичных результатов и т. д.).

Чтобы эффективно распараллелить цикл, желательно, чтобы его тело было **без побочных эффектов**, то есть не изменяло глобальные переменные и не зависело от общих ресурсов. В таком случае можно легко разделять работу между потоками без сложной синхронизации.

Аналогичное правило действует при рекурсивных вызовах: если каждая рекурсивная ветвь не зависит от остальных, вычисления легко распараллеливаются (например, рекурсивные обходы деревьев, divide-and-conquer алгоритмы).

*Особенно это актуально, если рекурсивно вычисляются элементы, не зависящие друг от друга (как в ряде Тейлора при подсчёте отдельных слагаемых).*

---

## Распараллеливание цикла

Рассмотрим задачу суммирования большого массива чисел. Последовательная реализация может выглядеть так:

```
double sum = 0.0;
for (int i = 0; i < n; i++) {
    sum += arr[i];
}
```

Чтобы распараллелить:
- Создают несколько потоков,
- Каждый поток обрабатывает часть данных (блочно или шагово),
- Собирают частичные суммы в итоговый результат.

Основные приёмы параллельного суммирования:
1. **“Пирамидка” (дерево суммирования)**: сначала потоки вычисляют свои локальные суммы, затем эти суммы объединяются в дереве редукции, уменьшая накладные расходы на синхронизацию.
2. **“Блоки”**: каждый поток получает непрерывный блок массива (например, первый поток считает от 0 до k-1 элемент, второй от k до 2k-1 и т.д.).
3. **Дополнительная память**: вместо общей глобальной переменной sum, которая требует синхронизации, у каждого потока своя локальная переменная. После окончания работы потоков результаты суммируются в одном потоке.

---

## Варианты сегментирования: блочный и шаговый

- **Блочный (block partitioning)**: массив делится на последовательные блоки (например, если n = 1000 и потоков 4, то потоку №1 достаются индексы [0..249], потоку №2 [250..499], и т.д.).
- **Шаговый (cyclic / interleaving)**: поток №1 обрабатывает индексы 0, 4, 8, 12..., поток №2 — 1, 5, 9, 13..., поток №3 — 2, 6, 10, 14..., поток №4 — 3, 7, 11, 15.... Такой подход бывает полезен, если данные сильно «кластеризованы» и хочется распределить нагрузку более равномерно.

---

## Суммирование рядов. Сходимость. Погрешность. Сегментация как переход к сумме конечного ряда

Многие бесконечные ряды (например, ряды для функций $\sin x$, $\ln x$ и т. п.) можно приближённо вычислять, беря лишь первые `N` слагаемых, при этом контролируя погрешность.  

*Чем быстрее убывает абсолютная величина последующих членов, тем меньше `N` нужно. Иногда учитывают остаточный член (оценку хвоста ряда), чтобы гарантировать нужную точность.*  

Чтобы распараллелить вычисление ряда, можно разбивать эти `N` слагаемых между несколькими потоками (аналогично сумме массива). Важно понимать, насколько быстро сходится ряд, чтобы правильно выбрать `N`.

*Если ряд сходится медленно, нужно задействовать больше потоков, но при этом следить за накоплением погрешности при суммировании очень большого количества членов.*

---

## Тригонометрические функции. Ряд Тейлора. Рекуррентные отношения. Эффективность распараллеливания

Тригонометрические и экспоненциальные функции часто вычисляют через ряды Тейлора или рекуррентные формулы:
$
\sin x = \sum_{k=0}^{\infty} (-1)^k \frac{x^{2k+1}}{(2k+1)!}, 
\quad
\cos x = \sum_{k=0}^{\infty} (-1)^k \frac{x^{2k}}{(2k)!},
$
и так далее.

*Число необходимых членов ряда Тейлора зависит от величины `x` и требуемой точности, поскольку для больших `x` степени $x^{n}$ растут быстрее. Часто применяются приёмы вычисления синуса и косинуса с помощью редукции аргумента (приведения `x` к меньшему интервалу, например, $[-\pi, \pi]$), чтобы улучшить сходимость.*

Для распараллеливания ряда Тейлора применяют тот же принцип: раздать группам потоков различные наборы членов ряда и аккуратно собрать результат. Но часто практичнее использовать высокопроизводительные библиотеки (например, из «math»-пакетов или специализированных библиотек на С/С++ с векторизацией), чем писать собственную распараллеленную реализацию тригонометрии.

Иногда выгоднее использовать **рекуррентные отношения** (например, для вычисления $\sin(x+\Delta)$ через $\sin x$ и $\cos x$, если их можно эффективно распараллелить или векторизовать.


При больших объёмах вычислений такие рекуррентные формулы позволяют сократить операцию возведения в степень и факториалы, что положительно влияет на скорость.  

---
Метод `join` позволяет одному потоку ждать завершения другого. Если `t` это `Thread` объект, поток которого в данный момент выполняется,

`t.join()`;

заставляет текущий поток приостанавливать выполнение до тех пор, пока `t` поток не завершится. Перегрузки `join` позволяют программисту указать период ожидания. Однако, как и в случае с `sleep`, `join` зависит от ОС для синхронизации, поэтому не следует предполагать, что `join` будет ждать ровно столько, сколько вы укажете.

Как и `sleep`, `join` реагирует на прерывание выходом с `InterruptedException`.

---
Публичный статический интерфейс `Thread.UncaughtExceptionHandler`


Интерфейс для обработчиков, вызываемых при внезапном завершении потока из-за неперехваченного исключения. Когда поток собирается завершиться из-за неперехваченного исключения, виртуальная машина `Java` запросит у потока его `UncaughtExceptionHandler` с помощью `Threada.getUncughtExceptionHandler()` и вызовет метод обработчика `uncaughtException`, передав поток и исключение в качестве аргументов. Если поток не имеет своего `UncaughtExceptionHandler` явно установленного, то его объект `ThreadGroup` действует как его `UncaughtExceptionHandler`. Если объект `ThreadGroup` не имеет особых требований для обработки исключения, он может перенаправить вызов обработчику неперехваченных исключений по умолчанию .

# <a name="лекиця-5"></a>Лекция 5

## Вычисление определённого интеграла

Для численного интегрирования 
$$
\int_a^b f(x)\,dx
$$
часто используют:
1. **Метод прямоугольников (метод Римана)**,
2. **Метод трапеций**,
3. **Более сложные методы (Симпсона, Гаусса и т. п.)**.

Чтобы увеличить точность, повышают число разбиений отрезка $[a,b]$. В параллельном варианте:

- Делят исходный отрезок на несколько подотрезков,
- Запускают несколько потоков, каждый считает свою часть интеграла,
- Суммируют все части.

Таким образом, есть два основных способа:

1. Разбить $[a,b]$ на большие блоки (каждому потоку свой блок).  
2. “Шаговая” схема, когда поток № $k$ считает точки $x_i$ с индексами, дающими остаток $k$ по модулю числа потоков.

![alt text](image-1.png)

$$
nF + (n - 1)Q
$$
где:

- $F$ — это условная «стоимость» одного вычисления функции $f(x)$,
- $Q$ — это условная «стоимость» одной операции сложения,
- $n$ — общее число разбиений (или вычислений значений $f(x)$).

При последовательном подсчёте (например, методом прямоугольников) получается, что надо $n$ раз вычислить $f(x)$ (значит, $nF$) и $n - 1$ раз сложить (значит, $(n - 1)Q$). Так и выходит 
$$
nF + (n - 1)Q.
$$

В параллельном случае на $N$ потоков формула
$$
\frac{n}{N}\,F \;+\; \Bigl(\frac{n - 2}{N} + 1\Bigr)Q
$$
отражает **среднюю нагрузку** на один поток, если мы равномерно распределим работу между потоками:

- Каждый поток делает примерно $\frac{n}{N}$ вычислений функции ($\tfrac{n}{N}F$).
- Внутри потока суммирование локальных результатов занимает порядка $\tfrac{n}{N}-1$ операций, а при слиянии (редукции) частичных сумм ещё нужно учесть несколько дополнительных сложений, что «в среднем» даёт 
$$
\Bigl(\tfrac{n - 2}{N} + 1\Bigr)Q.
$$

## Вычисление числа $\pi$

Существует масса способов параллельно вычислять $\pi$. Несколько популярных подходов:

1. **Через $ \arcsin(x)$ или ряды Лейбница**  
   Пример: $\pi = 4 \sum_{k=0}^{\infty} \frac{(-1)^k}{2k+1}$.  
   Как и прежде, достаточно распараллелить сумму ряда.

2. **Определённый интеграл функции круга**  
   $\pi = 4 \int_0^1 \sqrt{1 - x^2}\,dx$.  
   Делим отрезок $[0,1]$ на подотрезки и распараллеливаем вычисление.

3. **Площадь круга как многогранника**  
   Приближаем окружность многоугольником с большим количеством сторон. Чем больше сторон, тем ближе площадь к $\pi \cdot R^2$. Задачу подсчёта вершин и площадей тоже можно распараллелить.

4. **Метод Монте-Карло**  
   Равномерно “бросаем точки” в квадрат $[0,1]\times[0,1]$. Доля точек, попавших внутрь четверти единичного круга, стремится к $\pi/4$. Генерация и подсчёт внутри круга прекрасно распараллеливаются.

5. **Метод интегрирования единичной функции**  
   В квадрате $[0,1]\times[0,1]$ интегрируем индикаторную функцию круга. По сути, это та же идея Монте-Карло, только в других формулировках.

---
`Callable<O>` возвращает результат


`Future` абстрация над задачей представляет собой результат асинхронного вычисления. Предоставляются методы для проверки завершения вычисления, ожидания его завершения и извлечения результата вычисления.

Результат можно извлечь только с помощью метода `get` , когда вычисление завершено, блокируя при необходимости до тех пор, пока оно не будет готово. Отмена выполняется методом `cancel` . Предоставляются дополнительные методы для определения того, завершилась ли задача нормально или была отменена. После завершения вычисления его нельзя отменить. Если вы хотите использовать `Future` для возможности отмены, но не предоставлять пригодный для использования результат, вы можете объявить типы формы `Future<?>`и возвращать `null` как результат базовой задачи.

`.get()` выбрасывает:
 - `CancellationException` - если вычисление было отменено
 - `ExecutionException` - если вычисление вызвало исключение
 - `InterruptedException` - если текущий поток был прерван во время ожидания

`.get(long timeout,
     TimeUnit  unit)` выбрасывает тоже самое, но добавляется:
 - `TimeoutException`- если время ожидания истекло

`.isDone()` - Возвращает true , если эта задача завершена.

`.isCancelled()` - Возвращает значение true , если эта задача была отменена до ее нормального завершения.

`cancel(boolean force)` - Попытки отменить выполнение этой задачи. Эта попытка не удастся, если задача уже завершена, уже отменена или не может быть отменена по какой-либо другой причине. Если попытка успешна и эта задача не была запущена при вызове отмены , эта задача никогда не должна запускаться. Если задача уже запущена, то параметр force определяет, следует ли прерывать поток, выполняющий эту задачу, в попытке остановить задачу.

---
`public class FutureTask<T>`

Отменяемое асинхронное вычисление. Этот класс предоставляет базовую реализацию `Future`, с методами для запуска и отмены вычисления, запроса на завершение вычисления и извлечения результата вычисления. Результат может быть получен только после завершения вычисления; методы get будут блокироваться, если вычисление еще не завершено. После завершения вычисления его нельзя перезапустить или отменить (если только вычисление не вызвано с помощью `runAndReset()`).

A `FutureTask` может быть использован для обертывания объекта `Callable` или `Runnable`. Поскольку `FutureTask` реализует `Runnable`, `FutureTask` может быть передано `Executor` для выполнения.

# <a name="лекция-6"></a>Лекция 6

## Сортировка

Сортировка — одна из ключевых задач в алгоритмической практике
---

### 1. Пузырьковая сортировка (Bubble Sort)

1. **Идея**  
   - Последовательно «пробегаем» по массиву, сравниваем соседние элементы и меняем их местами, если левый больше правого.  
   - За один проход «всплывает» самый большой элемент, а общее число проходов — $n-1$ (где $n$ — длина массива).

2. **Последовательная сложность**  
   - В худшем и среднем случае $\;O(n^2)$.  
   - «Общая вычислительная мощность» (число сравнений/перестановок) порядка $\frac{n(n-1)}{2}$.


---

### 2. Сортировка слиянием (Merge Sort)

1. **Идея**  
   - Рекурсивно делим массив пополам, сортируем каждую половину, а затем «сливаем» два отсортированных подмассива.  
   - При слиянии двух упорядоченных массивов $(k)$ и $(m)$ потребуются $(k+m)$ сравнений/копирований в худшем случае.

2. **Последовательная сложность**  
   - $\;O(n \log n)$ в среднем и в худшем случае.  
   - «Общая вычислительная мощность» — порядка $n \log n$ сравнений и $\,n \log n$ вспомогательных операций копирования.

---

### 3. Чётно-нечётная сортировка (Odd-Even Sort)

1. **Идея**  
   - Алгоритм похоже на пузырьковую сортировку, но на каждом шаге «попарно» обрабатываются либо все чётные индексы с их соседями (чёт-нечёт), либо все нечётные индексы с их соседями (нечёт-чёт).  
   - Меняем элементы местами, если они не в порядке.

2. **Последовательная сложность**  
   - $\;O(n^2)$ в худшем случае.  
   - Фактически это вид «пузырьковой» логики.

---

### 4. Быстрая сортировка (Quick Sort)

1. **Идея**  
   - Выбираем опорный элемент (pivot).  
   - Разделяем (partition) массив на часть с элементами меньше pivot и часть с элементами больше pivot.  
   - Рекурсивно сортируем левую и правую части.

2. **Последовательная сложность**  
   - Средний случай: $\;O(n \log n)$.  
   - Худший случай: $\;O(n^2)$ (если pivot неудачно выбирается каждый раз).  
   - «Общая вычислительная мощность» в среднем ~$2n \log n$ операций сравнения/обмена.


# <a name="лекция-7"></a>Лекция 7

## Мониторы
Монитр - объект, которым единовремменно мождеть владеть только один потокю

Чтобы сделать метод синхронизированным, добавить `synchronized` ключевое слово к его объявлению

Когда поток вызывает метод `wait()` по отношению к объекту, то поток приостанавливается и добавляется в набор ожидания для ожидания, пока какой-либо другой поток не вызовет `notify()` или `notifyAll()` для того же объекта.

Метод `notify()` используется для пробуждения потоков, которые находятся в наборе ожидания монитора определенного объекта. Существует два способа уведомления ожидающих потоков.

- `notify()` → Для всех потоков, ожидающих на wait, метод notify() уведомляет любого из них о необходимости пробуждения произвольно. Выбор того, какой именно поток следует пробуждать, недетерминирован и зависит от JVM.
- `notifyAll()` → Этот метод просто пробуждает все потоки, ожидающие в наборе ожидания. Пробужденные потоки не смогут продолжить работу, пока текущий поток не снимет блокировку с этого объекта. Пробужденные потоки будут конкурировать обычным образом с любыми другими потоками, которые могут активно конкурировать за синхронизацию.


Доступ к кэшу быстрее, поэтому из них считаем. Кэш у каждого ядра свой. Из-за `synchronized` и `volatile` работает медленее, так как каждый раз обращается к оперативке.

Критическая секция - секция алгоритма, которая должна выполняться только в одном потоке в каждый момент времени.


## Семафоры

Почти блокировка, стопор. Обладает счетчикомю. Можно один раз войти и много раз выйти.

`permits` - начальное количество доступных разрешений. Это значение может быть отрицательным, в этом случае выпуски должны произойти до того, как будут предоставлены какие-либо приобретения.
 Каждый `acquire()` блокирует при необходимости, пока разрешение не станет доступным, а затем берет его. Каждый `release()` добавляет разрешение, потенциально освобождая блокирующего приобретателя. Однако фактические объекты разрешений не используются; `Semaphore` просто ведет подсчет доступного числа и действует соответствующим образом.

 Перед получением элемента каждый поток должен получить разрешение от семафора, гарантирующее, что элемент доступен для использования. Когда поток заканчивает работу с элементом, он возвращается обратно в пул, а разрешение возвращается в семафор, позволяя другому потоку получить этот элемент. При `acquire()` вызове не удерживается блокировка синхронизации, поскольку это помешало бы возврату элемента в пул. Семафор инкапсулирует синхронизацию, необходимую для ограничения доступа к пулу, отдельно от любой синхронизации, необходимой для поддержания согласованности самого пула.

 Если установлено значение `false`, этот класс не дает никаких гарантий относительно порядка, в котором потоки получают разрешения. В частности, разрешено вклинивание , то есть вызывающему потоку `acquire()` может быть выделено разрешение раньше потока, который ожидал — логически новый поток помещает себя во главе очереди ожидающих потоков. Если справедливость установлена ​​в `true`, семафор гарантирует, что потоки, вызывающие любой из `acquire` методов, выбираются для получения разрешений в том порядке, в котором был обработан их вызов этих методов (первым пришел — первым вышел; FIFO).

 `tryAcquire ()` Получает разрешение, если таковое имеется, и немедленно возвращает его со значением `true`, уменьшая количество доступных разрешений на одно. Если разрешение отсутствует, то этот метод немедленно вернет значение `false`.

## happens-before 

 - Каждое действие в потоке происходит раньше каждого действия в этом потоке, которое происходит позже в порядке выполнения программы.
 - Разблокировка ( `synchronized` выход из блока или метода) монитора происходит перед каждой последующей блокировкой ( `synchronized` входом из блока или метода) того же монитора. И поскольку отношение происходит-перед является транзитивным, все действия потока до разблокировки происходят перед всеми действиями, следующими за блокировкой любого потока этого монитора.
 - Запись в `volatile` поле происходит перед каждым последующим чтением этого же поля. Записи и чтения `volatile` полей имеют такие же эффекты согласованности памяти, как вход и выход из мониторов, но не влекут за собой блокировку взаимного исключения.
 - Вызов в `start` потоке происходит до любого действия в запущенном потоке.
 - Все действия в потоке происходят до того, как любой другой поток успешно вернется из `join` этого потока.

## Lock

`Lock` — это интерфейс в Java, предоставляющий механизм эксклюзивного или совместного доступа к разделяемому ресурсу. Он расширяет возможности встроенной синхронизации (`synchronized`) за счёт:

- Гибкого управления блокировками (можно вызывать `lock()` и `unlock()` в разных местах кода).
- Поддержки нескольких методов блокировки (прерываемая, с таймаутом и т. д.).
- Возможности использования нескольких объектов `Condition` для одного `Lock`.

Эксклюзиная и неэксклюзивная блокировка

`readLock()`, `writeLock()`
---

### Идиома использования `Lock`

Самая распространённая **идиома** безопасного использования `Lock` в Java основана на конструкции `try/finally`:

```java
Lock lock = ...;
lock.lock();
try {
    // Код, работающий с общим ресурсом,
    // который защищён этой блокировкой
} finally {
    lock.unlock();  // Снятие блокировки, даже если было исключение
}
```

# <a name="лекция-8"></a>Лекция 8



# <a name="синхронизированные-алгоритмы"></a>Синхронизированные алгоритмы

Ниже приводится обзор уровней не/блокирующих алгоритмов (obstruction-free, lock-free, wait-free), а также подходов к реализации коллекций (грубая, тонкая, оптимистичная, ленивая, неблокирующая). В завершение кратко рассмотрим принцип построения «очереди с корзинами» (basket queue).

---

## Уровни алгоритмов: obstruction-free, lock-free, wait-free

### Obstruction-free
Алгоритм считается obstruction-free, если при отсутствии конфликтов (то есть когда поток выполняется «в одиночестве», без помех со стороны других потоков) он гарантированно завершит операцию за конечное время. При появлении конфликтов и вмешательстве других потоков алгоритм может прерываться и начинать операцию заново.

### Lock-free
Lock-free гарантирует, что система (по крайней мере один поток) будет совершать прогресс за конечное число шагов, даже если несколько потоков одновременно обращаются к ресурсу и могут мешать друг другу. Сам поток, который находится в конфликте, может неоднократно повторять операцию (CAS не прошёл), но всегда есть вероятность, что она у него получится, либо получится у другого потока.

### Wait-free
Wait-free обеспечивает гарантированный прогресс **каждого** потока за конечное число шагов, независимо от деятельности других потоков. Это наиболее «сильная» гарантия не/блокирующей синхронизации. В реальных структурах данных (особенно сложных) встретить полный wait-free сложнее всего.

---

## Реализация коллекций: грубая, тонкая, оптимистичная, ленивая, неблокирующая

### Грубая (coarse-grained)
Коллекция использует одну большую блокировку (например, один `synchronized` на всю структуру). Каждый вызов любого метода (добавление, удаление, поиск и т. д.) блокирует всю коллекцию и освобождает её после завершения операции. Таким образом, операции «по очереди» получают доступ к структуре.

### Тонкая (fine-grained)
Коллекция делится на части (сегменты, узлы, блоки), и каждая часть блокируется отдельно (собственный `Lock` или `synchronized`). Если поток работает с определённым сегментом, остальные сегменты остаются открыты для других потоков. Это повышает степень параллелизма. Пример — сегментированная мапа, где каждая группа корзин (bucket) имеет собственную блокировку.

### Оптимистичная (optimistic)
Предполагает, что конфликты в структуре редки. Поток читает или готовит данные, потом проверяет, не изменилась ли структура за время чтения (например, с помощью CAS или сравнения версионного штампа). Если изменений не было, фиксирует изменения. Если кто-то уже успел модифицировать структуру, операция откатывается и повторяется. Такое «предположительно без блокировок» чтение ускоряет обработку, когда реальных конфликтов мало.

### Ленивая (lazy)
Некоторые операции (обычно удаление) откладывают освобождение ресурсов. Например, в списке удаляемый элемент не сразу исключается физически, а лишь помечается как «неактуальный» (marked = true). При дальнейшем обходе структуры «получившие пометку» элементы окончательно удаляются. Такой подход сокращает время, затрачиваемое непосредственно в операции удаления.

### Неблокирующая (non-blocking)
Для управления структурой данных (очереди, стеки, списки) применяются атомарные операции (CAS), без использования стандартных `Lock`/`synchronized`. Поток читает текущее состояние (например, указатель на голову списка), вычисляет новое и пытается записать его обратно через CAS. Если другие потоки успели изменить состояние, CAS не проходит, и операция повторяется. Так достигается lock-free (а иногда и wait-free) работа со структурой.

---

## Коллекции на AtomicReference

Многие неблокирующие структуры данных (стек, очередь, список) могут быть построены с помощью `AtomicReference` для хранения следующего узла или головного указателя. При вставке (или удалении) поток формирует новое состояние и делает CAS над текущим указателем. Если CAS прошёл, операция успешно завершена, если нет — поток снова читает актуальное состояние и повторяет попытку.

```java
class Node<E> {
    E value;
    AtomicReference<Node<E>> next;
}

class LockFreeStack<E> {
    private AtomicReference<Node<E>> head = new AtomicReference<>(null);

    public void push(E val) {
        Node<E> newNode = new Node<>(val);
        Node<E> oldHead;
        do {
            oldHead = head.get();
            newNode.next.set(oldHead);
        } while (!head.compareAndSet(oldHead, newNode));
    }

    public E pop() {
        Node<E> oldHead;
        Node<E> newHead;
        do {
            oldHead = head.get();
            if (oldHead == null) {
                return null; // stack is empty
            }
            newHead = oldHead.next.get();
        } while (!head.compareAndSet(oldHead, newHead));
        return oldHead.value;
    }
}
```

---

## Очередь с корзинами (basket queue)

Очередь делится на небольшие «корзины» (baskets). Каждая корзина может сама быть реализована как небольшая lock-free структура (например, на атомарных ссылках). При добавлении (enqueue) поток выбирает корзину, в которой есть место (по индексу, по round-robin, по хешу) и выполняет вставку. Если корзина заполнена, поток переключается на другую. При извлечении (dequeue) поток ищет корзину, где есть элементы, и забирает один. Благодаря распределению по корзинам в систему вводится возможность параллельного добавления и извлечения нескольких элементов разными потоками без централизации на одном указателе.

---

# Итог

- **Obstruction-free** гарантирует прогресс при «одиночном» исполнении.  
- **Lock-free** обеспечивает глобальный прогресс, исключая ситуацию, когда система “застывает” из-за одного проблемного потока.  
- **Wait-free** гарантирует прогресс всем потокам за конечное время.  

Коллекции могут быть реализованы с разной степенью гранулярности синхронизации: грубая (одна блокировка), тонкая (блокировки на сегментах), оптимистичная (проверка изменений в конце), ленивая (отложенное освобождение элементов) и неблокирующая (CAS-операции). Применение `AtomicReference` лежит в основе lock-free и wait-free структур, а «очередь с корзинами» является одним из вариантов улучшения пропускной способности и параллелизма за счёт разбиения данных на независимые сегменты.

# <a name="взаимное-исключение-в-распределённых-системах"></a>Взаимное исключение в распределённых системах

Взаимное исключение (mutual exclusion) — это механизм, который гарантирует, что общий ресурс не будет одновременно использоваться несколькими процессами. В классической (локальной) среде эту задачу решают посредством блокировок, семафоров и т.д. В **распределённых системах** реализация взаимного исключения усложняется из-за необходимости обмена сообщениями по сети, отсутствия общего физического адресного пространства и непредсказуемостей (задержки, сбои узлов, сетевые разделы).

---

## Сложность реализации в распределённых системах

1. **Нет общего памяти и единого временного штампа**  
   Взаимодействие между процессами идёт через обмен сообщениями. Нужно строить протоколы, учитывающие возможные сетевые задержки и отсутствие глобальных синхронизированных часов.

2. **Сбои и непредсказуемое сетевое поведение**  
   Участники могут «отвалиться» или «зависнуть», при этом не всегда очевидно, жив ли узел или просто временно потерял связь. Требуются механизмы обнаружения отказов (failure detection) и повторных запросов.

3. **Необходимость выбора координатора или распределённой договорённости**  
   При централизованных решениях узел-координатор управляет доступом к ресурсу. При его сбое нужно быстро выбрать нового координатора. В децентрализованных решениях важен консенсус между всеми узлами.

4. **Опасность взаимоблокировок (deadlock) или «голодания» (starvation)**  
   Требуется аккуратная логика протокола, чтобы не возникало циклов ожидания и чтобы каждый процесс в конечном итоге получал доступ к ресурсу.

---

## Задача обедающих философов

В контексте **распределённых систем** задачу обедающих философов можно трактовать как ситуацию, где несколько распределённых процессов (философов) хотят получить доступ к разделяемым ресурсам (вилки) для выполнения критической секции (приёма пищи). Каждый философ:
1. Запрашивает доступ к вилкам (ресурсам).
2. Если вилки свободны — начинает «есть» (заходит в критическую секцию).
3. Освобождает вилки по окончании.

В распределённом варианте «вилки» могут быть физически разнесены, а философы — это удалённые узлы. Протокол должен:
- Исключать одновременный доступ к одной вилке несколькими философами.  
- Правильно обрабатывать ситуации, когда узлы посылают запросы на ресурсы по сети.

Этот классический пример демонстрирует потенциальные проблемы: тупики, голодание, проблемы с координацией.

---

## Централизованные алгоритмы

### 1. Алгоритм с координатором (Central server)
Один узел объявляется координатором. Любой процесс, желающий войти в критическую секцию, отправляет ему запрос:
1. Координатор, получив запрос на ресурс, проверяет, свободен ли он.
2. Если ресурс свободен, даёт «разрешение» на вход в критическую секцию, а ресурс отмечается занятым.
3. Если ресурс занят, запрос ставится в очередь. Координатор, освободив ресурс, разрешает доступ следующему по очереди.
4. По завершении работы в критической секции процесс посылает координатору уведомление об освобождении ресурса.

### 2. Изменение координатора при его сбое
Если координатор выходит из строя, надо выбрать нового. Примером может служить алгоритм «bully» или «Ring Election Algorithm». После выбора нового координатора запросы на доступ к ресурсу направляют уже ему.

В результате все процессы знают «центр», через который проходят все запросы на взаимное исключение.

---

## Децентрализованные алгоритмы

### 1. Алгоритм на основе распределённого согласования (Ricart–Agrawala)
Каждый процесс, желая войти в критическую секцию, рассылает запрос всем другим процессам:
1. Запрос содержит логический временной штамп (Lamport timestamp), чтобы упорядочить очереди.
2. Получая запрос, процесс принимает решение, можно ли немедленно ответить «ОК» (если сам не претендует на ресурс или у него запрос с более поздним штампом).  
3. Процесс входит в критическую секцию, когда получил «ОК» от всех.  
4. По выходе из критической секции рассылает уведомления, позволяющие другим процессам двигаться дальше.

Здесь нет единого координатора, порядок поддерживается логическими часами и взаимными подтверждениями.

### 2. Алгоритм распределённого дерева
Существует структура-дерево (или логическая кольцевая топология). Узел, желая войти в критическую секцию, отправляет запрос соседу, тот — своему соседу и т.д., пока запрос не достигнет владельца ресурса. После освобождения ресурс передаётся следующему по дереву. Так достигается децентрализация: нет центральной точки, в которой бы концентрировались все запросы. При сбоях таких алгоритмов важно уметь перестраивать дерево или кольцо.

---

# Итог

Реализация взаимного исключения в распределённой среде требует специальных алгоритмов, учитывающих отсутствие общей памяти, возможные сетевые задержки, сбои узлов и необходимость достижения согласия между независимыми процессами. Централизованные решения используют единый узел-координатор, который управляет ресурсом, а децентрализованные распределяют логику по всем участникам (через взаимные обмены сообщениями и логику упорядочения). Классическая задача обедающих философов хорошо иллюстрирует проблемы, с которыми сталкиваются процессы, конкурирующие за распределённые ресурсы.

# <a name="асинхронная-разработка"></a>Асинхронная разработка

Асинхронная модель работы позволяет выполнять операции, не блокируя основной поток. Если операция требует долгого ожидания (сетевой запрос, чтение из файловой системы, обращение к базе данных), поток не «замораживается» на всё время ожидания, а может обрабатывать другие задачи. Ниже перечислены основные аспекты асинхронной разработки в контексте Java: проблемы блокирующих алгоритмов, использование колбэков, `CompletableFuture` и реактивное программирование.

---

## Проблемы блокирующих алгоритмов

### Блокировка потока при долгих операциях
Когда поток выполняет запрос к удалённому сервису, базе данных или файловой системе в синхронном (блокирующем) режиме, он вынужден ждать ответа. Это ведёт к тому, что поток простаивает, в то время как можно было бы заняться другими задачами.

### Ограничение числа потоков
Всякий поток — это ограниченный ресурс. Если приложение для каждого ожидания порождает отдельный поток, возрастает нагрузка на планировщик ОС и растут накладные расходы (контекстные переключения, память под стеки). При очень большом числе одновременных блокировок производительность резко падает.

### Сложность масштабирования
В системах с высокими нагрузками блокирующие вызовы затрудняют масштабирование: можно добавить больше аппаратных ресурсов (CPU, оперативной памяти), но если основной поток постоянно ждёт, рост производительности не проявится.

---

## Callback

### Суть колбэков
Колбэки (обратные вызовы) — это функция (или метод), которая передаётся куда-то (например, в асинхронный метод) и вызывается при завершении операции. Вместо того, чтобы блокироваться, основной поток назначает колбэк и продолжает работу. По окончании фоновой (долгой) операции колбэк уведомляет, что данные готовы.

Пример (обобщённый псевдокод):
```
void asyncOperation(Callback callback) {
    // запускаем асинхронную задачу
    // когда закончится, вызываем:
    callback.onComplete(result);
}
```

### Применение в Java
В Java колбэки часто используются при работе с асинхронными фреймворками (Netty, Vert.x), а также при работе с GUI (например, в Swing).

### Проблема «адского дерева колбэков»
При сложных сценариях (выполнить задачу А, затем задачу B, затем задачу C…) колбэки могут вкладываться друг в друга, образуя «пирамиду» громоздкого кода, которую трудно читать и поддерживать. Для решения в Java используют `CompletableFuture` или реактивные подходы, где можно связывать несколько асинхронных операций линейно или через композицию.

---

## CompletableFuture и thenApplyAsync()

### Основные возможности
`CompletableFuture` — класс из Java, позволяющий работать с асинхронными задачами без глубоких «вложенных» колбэков. Можно запустить задачу, вернув `CompletableFuture`, и затем «повесить» на неё цепочку зависимых операций.

Пример (упрощённый):
```java
CompletableFuture.supplyAsync(() -> {
    // долгий код, например запрос к базе
    return "data";
}).thenApplyAsync(data -> {
    // ещё одна асинхронная обработка
    return data.toUpperCase();
}).thenAcceptAsync(result -> {
    // завершающее действие
    System.out.println("Result: " + result);
});
```

### Управление потоками
- `supplyAsync()` использует пул потоков (ForkJoinPool или кастомный Executor).
- `thenApplyAsync()`, `thenAcceptAsync()`, `thenComposeAsync()` и другие методы позволяют указать, что следующий колбэк тоже будет выполняться в пуле потоков асинхронно.
- При необходимости можно передавать свой `Executor`, чтобы контролировать, где именно исполняются дальнейшие этапы.

### Сцепка нескольких асинхронных вызовов
Можно объединять несколько `CompletableFuture`:
- `thenCompose(...)` для последовательной зависимости (результат одной задачи передаётся в следующую).
- `thenCombine(...)` для параллельных задач, чей результат объединяется.

---

## Реактивное программирование

### Принцип работы
Реактивное программирование базируется на потоке данных и концепции «наблюдатель» (observer) или «подписчик» (subscriber). Код выражается в виде цепочек операторов, где каждый оператор может преобразовывать, фильтровать или агрегировать события, поступающие асинхронно.

### Основные понятия
- **Observable/Flux/Flowable**: источник данных (стрим событий).
- **Observer/Subscriber**: потребитель данных (подписывается на события).
- **Operators**: промежуточные преобразования (map, filter, reduce и т.д.).

### Реализации в Java
- **Project Reactor** (используется в Spring WebFlux).
- **RxJava** (пакет операторов, вдохновлённый Reactive Extensions).
- **Mutiny, Akka Streams**, и др. в экосистеме Java/Scala.

### Пример (на Project Reactor)
```java
Flux.just("alpha", "beta", "gamma")
    .map(String::toUpperCase)
    .filter(str -> str.startsWith("A"))
    .subscribe(item -> System.out.println("Got: " + item));
```
Здесь нет прямых блокировок: «поток» данных проходит через цепочку операторов, и при появлении нового элемента вызывается `subscribe`.

---

# Итог

В асинхронной разработке важно уходить от блокирующих вызовов, чтобы не простаивали потоки при долгих операциях. Для этого используются:
- **Callback**: классический способ зарегистрировать обратный вызов, который сработает по завершении операции.
- **CompletableFuture**: даёт удобные методы (`thenApplyAsync()`, `thenAcceptAsync()`) для формирования последовательностей асинхронных действий.
- **Реактивное программирование**: строит реактивные «потоки» данных (Flux, Mono, Flowable) и позволяет работать с асинхронными событиями в виде конвейеров операторов, упрощая управление сложными асинхронными сценариями.

# <a name="ссылки"></a>Ссылки на ресурсы

 - [Threads](https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html)
 - 